{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Welcome to the documentation for ZarrNii, a Python library for working with OME-Zarr and NIfTI formats. ZarrNii bridges the gap between these two popular formats, enabling seamless data transformation, metadata preservation, and efficient processing of large biomedical images.</p>"},{"location":"#what-is-zarrnii","title":"What is ZarrNii?","text":"<p>ZarrNii is designed for researchers and engineers working with:</p> <ul> <li>OME-Zarr: A format for storing multidimensional image data, commonly used in microscopy.</li> <li>NIfTI: A standard format for neuroimaging data.</li> </ul> <p>ZarrNii allows you to:</p> <ul> <li>Read and write OME-Zarr and NIfTI datasets.</li> <li>Perform transformations like cropping, downsampling, and interpolation.</li> <li>Preserve and manipulate metadata from OME-Zarr (e.g., axes, coordinate transformations, OME annotations).</li> </ul>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Seamless Format Conversion: Easily convert between OME-Zarr and NIfTI while preserving spatial metadata.</li> <li>Transformations: Apply common operations like affine transformations, downsampling, and upsampling.</li> <li>Multiscale Support: Work with multiscale OME-Zarr pyramids.</li> <li>Metadata Handling: Access and modify OME-Zarr metadata like axes and transformations.</li> <li>Lazy Loading: Leverage Dask arrays for efficient processing of large datasets.</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>from zarrnii import ZarrNii\n\n# Load an OME-Zarr dataset\nznimg = ZarrNii.from_ome_zarr(\"path/to/zarr_dataset.ome.zarr\")\n\n# Perform a transformation (e.g., downsample)\ndownsampled_znimg = znimg.downsample(level=2)\n\n# Save as NIfTI\ndownsampled_znimg.to_nifti(\"output_dataset.nii\")\n</code></pre>"},{"location":"#learn-more","title":"Learn More","text":"<p>Explore the documentation to get started:</p> <ul> <li>Walkthrough: Overview: Understand the core concepts.</li> <li>API Reference: Dive into the technical details.</li> <li>Examples: Learn through practical examples.</li> <li>FAQ: Find answers to common questions.</li> </ul>"},{"location":"faq/","title":"FAQ: Frequently Asked Questions","text":"<p>This page addresses common questions and provides troubleshooting tips for using ZarrNii.</p>"},{"location":"faq/#general-questions","title":"General Questions","text":""},{"location":"faq/#1-what-is-zarrnii","title":"1. What is ZarrNii?","text":"<p>ZarrNii is a Python library that bridges the gap between OME-Zarr and NIfTI formats, enabling seamless conversion, transformations, and metadata handling for multidimensional biomedical images.</p>"},{"location":"faq/#2-what-formats-does-zarrnii-support","title":"2. What formats does ZarrNii support?","text":"<p>ZarrNii supports: - OME-Zarr: A format for storing chunked, multidimensional microscopy images. - NIfTI: A format commonly used for neuroimaging data.</p>"},{"location":"faq/#3-can-zarrnii-handle-large-datasets","title":"3. Can ZarrNii handle large datasets?","text":"<p>Yes! ZarrNii uses Dask arrays to handle datasets that don't fit into memory. Most transformations are lazy, meaning computations are only performed when explicitly triggered using <code>.compute()</code>.</p>"},{"location":"faq/#installation-issues","title":"Installation Issues","text":""},{"location":"faq/#1-i-installed-zarrnii-but-i-cant-import-it","title":"1. I installed ZarrNii, but I can't import it.","text":"<p>Ensure that ZarrNii is installed in the correct Python environment. Use <code>poetry show</code> or <code>pip show zarrnii</code> to verify the installation.</p> <p>If you're still encountering issues, try reinstalling the library:</p> <pre><code>poetry install\n</code></pre>"},{"location":"faq/#troubleshooting","title":"Troubleshooting","text":""},{"location":"faq/#performance-tips","title":"Performance Tips","text":""},{"location":"faq/#1-how-can-i-speed-up-transformations-on-large-datasets","title":"1. How can I speed up transformations on large datasets?","text":"<ul> <li>Use appropriate chunk sizes with <code>.rechunk()</code> for operations like downsampling or interpolation.</li> <li>Trigger computations only when necessary using <code>.compute()</code>.</li> </ul>"},{"location":"faq/#2-how-do-i-optimize-multiscale-processing","title":"2. How do I optimize multiscale processing?","text":"<p>For OME-Zarr datasets with multiscale pyramids: 1. Use the appropriate <code>level</code> when loading the dataset.</p> <pre><code>znimg = ZarrNii.from_ome_zarr(\"path/to/dataset.zarr\", level=2)\n</code></pre>"},{"location":"faq/#metadata-questions","title":"Metadata Questions","text":""},{"location":"faq/#1-how-do-i-access-ome-zarr-metadata","title":"1. How do I access OME-Zarr metadata?","text":"<p>ZarrNii provides attributes for accessing metadata:</p> <pre><code>print(\"Axes:\", znimg.axes)\nprint(\"Coordinate transformations:\", znimg.coordinate_transformations)\nprint(\"Omero metadata:\", znimg.omero)\n</code></pre>"},{"location":"faq/#2-does-zarrnii-preserve-metadata-during-transformations","title":"2. Does ZarrNii preserve metadata during transformations?","text":"<p>Yes, ZarrNii updates the metadata to remain consistent with transformations like cropping, downsampling, or affine transformations.</p>"},{"location":"faq/#getting-help","title":"Getting Help","text":"<p>If you encounter issues not covered here: 1. Check the API Reference for detailed information about ZarrNii methods. 2. Open an issue on the GitHub repository.</p>"},{"location":"faq/#summary","title":"Summary","text":"<p>This FAQ covers common questions about ZarrNii, troubleshooting tips, and best practices for working with large datasets and metadata. For more in-depth information, explore: - Examples - API Reference</p>"},{"location":"reference/","title":"API Reference","text":"<p>This page documents the core classes, methods, and functions in ZarrNii. </p>"},{"location":"reference/#core-classes","title":"Core Classes","text":""},{"location":"reference/#zarrnii","title":"ZarrNii","text":"<p>The <code>ZarrNii</code> class provides tools for reading, writing, and transforming datasets in OME-Zarr and NIfTI formats.</p>"},{"location":"reference/#key-methods","title":"Key Methods","text":"<ul> <li><code>from_ome_zarr</code>: Load data from OME-Zarr.</li> <li><code>from_nifti</code>: Load data from a NIfTI file.</li> <li><code>to_ome_zarr</code>: Save data as OME-Zarr.</li> <li><code>to_nifti</code>: Save data as a NIfTI file.</li> <li><code>downsample</code>: Reduce resolution of datasets.</li> <li><code>upsample</code>: Increase resolution of datasets.</li> </ul> <p>Represents a Zarr-based image with NIfTI compatibility and OME-Zarr metadata.</p> <p>Attributes:</p> Name Type Description <code>darr</code> <code>Array</code> <p>The main dask array holding image data.</p> <code>affine</code> <code>AffineTransform</code> <p>The affine transformation matrix.</p> <code>axes_order</code> <code>str</code> <p>The order of the axes in the data array ('ZYX' or 'XYZ').</p> <code>axes</code> <code>Optional[List[Dict]]</code> <p>Metadata about the axes (from OME-Zarr).</p> <code>coordinate_transformations</code> <code>Optional[List[Dict]]</code> <p>Transformations applied to the data (from OME-Zarr metadata).</p> <code>omero</code> <code>Optional[Dict]</code> <p>Metadata related to visualization and channels (from OME-Zarr).</p>"},{"location":"reference/#methods","title":"Methods","text":""},{"location":"reference/#from_ome_zarr","title":"<code>from_ome_zarr</code>","text":"<p>Reads in an OME-Zarr file as a ZarrNii image, optionally as a reference.</p> <p>Parameters:</p> Name Type Description Default <code>store_or_path</code> <code>str</code> <p>Store or path to the OME-Zarr file.</p> required <code>level</code> <code>int</code> <p>Pyramid level to load (default: 0).</p> <code>0</code> <code>channels</code> <code>list</code> <p>Channels to load by index (default: None, loads all channels).</p> <code>None</code> <code>channel_labels</code> <code>list</code> <p>Channels to load by label name (default: None).</p> <code>None</code> <code>chunks</code> <code>str or tuple</code> <p>Chunk size for dask array (default: \"auto\").</p> <code>'auto'</code> <code>rechunk</code> <code>bool</code> <p>Whether to rechunk the data (default: False).</p> <code>False</code> <code>storage_options</code> <code>dict</code> <p>Storage options for Zarr.</p> <code>None</code> <code>orientation</code> <code>str</code> <p>Default input orientation if none is specified in metadata (default: 'IPL').</p> <code>'IPL'</code> <code>as_ref</code> <code>bool</code> <p>If True, creates an empty dask array with the correct shape instead of loading data.</p> <code>False</code> <code>zooms</code> <code>list or ndarray</code> <p>Target voxel spacing in xyz (only valid if as_ref=True).</p> <code>None</code> <p>Returns:</p> Name Type Description <code>ZarrNii</code> <p>A populated ZarrNii instance.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>zooms</code> is specified when <code>as_ref=False</code>.</p> <code>ValueError</code> <p>If both <code>channels</code> and <code>channel_labels</code> are specified.</p> <code>ValueError</code> <p>If <code>channel_labels</code> are specified but no omero metadata is found.</p> <code>ValueError</code> <p>If any specified channel label is not found in omero metadata.</p> Source code in <code>zarrnii/core.py</code> <pre><code>@classmethod\ndef from_ome_zarr(\n    cls,\n    store_or_path,\n    level=0,\n    channels=None,\n    channel_labels=None,\n    chunks=\"auto\",\n    rechunk=False,\n    storage_options=None,\n    orientation=\"IPL\",\n    as_ref=False,\n    zooms=None,\n):\n    \"\"\"\n    Reads in an OME-Zarr file as a ZarrNii image, optionally as a reference.\n\n    Parameters:\n        store_or_path (str): Store or path to the OME-Zarr file.\n        level (int): Pyramid level to load (default: 0).\n        channels (list): Channels to load by index (default: None, loads all channels).\n        channel_labels (list): Channels to load by label name (default: None).\n        chunks (str or tuple): Chunk size for dask array (default: \"auto\").\n        rechunk (bool): Whether to rechunk the data (default: False).\n        storage_options (dict): Storage options for Zarr.\n        orientation (str): Default input orientation if none is specified in metadata (default: 'IPL').\n        as_ref (bool): If True, creates an empty dask array with the correct shape instead of loading data.\n        zooms (list or np.ndarray): Target voxel spacing in xyz (only valid if as_ref=True).\n\n    Returns:\n        ZarrNii: A populated ZarrNii instance.\n\n    Raises:\n        ValueError: If `zooms` is specified when `as_ref=False`.\n        ValueError: If both `channels` and `channel_labels` are specified.\n        ValueError: If `channel_labels` are specified but no omero metadata is found.\n        ValueError: If any specified channel label is not found in omero metadata.\n    \"\"\"\n\n    if not as_ref and zooms is not None:\n        raise ValueError(\"`zooms` can only be used when `as_ref=True`.\")\n\n    if channels is not None and channel_labels is not None:\n        raise ValueError(\"Cannot specify both 'channels' and 'channel_labels'. Use one or the other.\")\n\n    # Determine the level and whether downsampling is required\n    if not as_ref:\n        (\n            level,\n            do_downsample,\n            downsampling_kwargs,\n        ) = cls.get_level_and_downsampling_kwargs(\n            store_or_path, level\n        )\n    else:\n        do_downsample = False\n\n\n    multiscales = nz.from_ngff_zarr(store_or_path)\n\n\n    # Read orientation metadata (default to `orientation` if not present)\n    group = zarr.open_group(store_or_path, mode='r')\n\n    orientation = group.attrs.get(\"orientation\", orientation)\n\n    # Handle channel selection - resolve labels to indices if needed\n    final_omero_metadata = multiscales.metadata.omero  # Default fallback\n    if channel_labels is not None:\n        # Try to get omero metadata from zarr group attributes directly\n        # since ngff-zarr sometimes doesn't load it properly\n        omero_metadata = None\n        if 'multiscales' in group.attrs:\n            multiscales_attrs = group.attrs['multiscales']\n            if isinstance(multiscales_attrs, list) and len(multiscales_attrs) &gt; 0:\n                omero_metadata = multiscales_attrs[0].get('omero')\n\n        if omero_metadata is None:\n            raise ValueError(\"Channel labels were specified but no omero metadata found in the OME-Zarr file.\")\n\n        # Extract channel labels from omero metadata\n        if 'channels' not in omero_metadata:\n            raise ValueError(\"No channel information found in omero metadata.\")\n\n        channel_info = omero_metadata['channels']\n        available_labels = [ch.get('label', '') for ch in channel_info]\n\n        # Resolve channel labels to indices\n        resolved_channels = []\n        for label in channel_labels:\n            try:\n                idx = available_labels.index(label)\n                resolved_channels.append(idx)\n            except ValueError:\n                raise ValueError(f\"Channel label '{label}' not found. Available labels: {available_labels}\")\n\n        channels = resolved_channels\n        final_omero_metadata = omero_metadata  # Use the properly loaded metadata\n    elif 'multiscales' in group.attrs:\n        # Even if channel_labels not specified, try to get proper omero metadata\n        multiscales_attrs = group.attrs['multiscales']\n        if isinstance(multiscales_attrs, list) and len(multiscales_attrs) &gt; 0:\n            group_omero = multiscales_attrs[0].get('omero')\n            if group_omero is not None:\n                final_omero_metadata = group_omero\n\n    # Get axis names\n    axis_names = [axis.name for axis in multiscales.metadata.axes]\n\n    # Determine index of 'c' axis\n    c_index = axis_names.index('c')\n\n    # If no channels specified, load all channels\n    if channels is None:\n        # Get total number of channels from the data shape\n        total_shape = multiscales.images[level].data.shape\n        num_channels = total_shape[c_index]\n        channels = list(range(num_channels))\n\n\n    # Build slices: 0 for 't' (drop it), channels for 'c', slice(None) for others\n    slices = []\n    for i, name in enumerate(axis_names):\n        if name == 't':\n            slices.append(0)  # Drop singleton time axis\n        elif name == 'c':\n            slices.append(channels)  # Select specific channel(s)\n        else:\n            slices.append(slice(None))  # Keep full range\n\n    # Apply the slices\n    darr_base = multiscales.images[level].data[tuple(slices)]\n\n\n    shape = darr_base.shape\n\n    coordinate_transformations = multiscales.metadata.datasets[level].coordinateTransformations\n\n    affine = cls.construct_affine(coordinate_transformations, orientation)\n\n    if zooms is not None:\n        # Handle zoom adjustments\n        in_zooms = np.sqrt(\n            (affine[:3, :3] ** 2).sum(axis=0)\n        )  # Current voxel spacing\n        scaling_factor = in_zooms / zooms\n        new_shape = [\n            shape[0],\n            int(np.floor(shape[1] * scaling_factor[2])),  # Z\n            int(np.floor(shape[2] * scaling_factor[1])),  # Y\n            int(np.floor(shape[3] * scaling_factor[0])),  # X\n        ]\n        np.fill_diagonal(affine[:3, :3], zooms)\n    else:\n        new_shape = shape\n\n    # we want to downsample *before* we rechunk\n\n    if as_ref:\n        # Create an empty array with the updated shape\n        darr = da.empty(new_shape, chunks=chunks, dtype=darr_base.dtype)\n    else:\n        darr = darr_base\n\n    znimg = cls(\n        darr,\n        affine=AffineTransform.from_array(affine),\n        axes_order=\"ZYX\",\n        axes=multiscales.metadata.axes,\n        coordinate_transformations=coordinate_transformations,\n        omero=final_omero_metadata, \n    )\n\n    if do_downsample:\n        znimg = znimg.downsample(**downsampling_kwargs)\n\n    if rechunk:\n        znimg.darr = znimg.darr.rechunk(chunks)\n\n    return znimg\n</code></pre>"},{"location":"reference/#from_nifti","title":"<code>from_nifti</code>","text":"<p>Creates a ZarrNii instance from a NIfTI file. Populates OME-Zarr metadata based on the NIfTI affine matrix.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the NIfTI file.</p> required <code>chunks</code> <code>str or tuple</code> <p>Chunk size for dask array (default: \"auto\").</p> <code>'auto'</code> <code>as_ref</code> <code>bool</code> <p>If True, creates an empty dask array with the correct shape instead of loading data.</p> <code>False</code> <code>zooms</code> <code>list or ndarray</code> <p>Target voxel spacing in xyz (only valid if as_ref=True).</p> <code>None</code> <p>Returns:</p> Name Type Description <code>ZarrNii</code> <p>A populated ZarrNii instance.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>zooms</code> is specified when <code>as_ref=False</code>.</p> Source code in <code>zarrnii/core.py</code> <pre><code>@classmethod\ndef from_nifti(cls, path, chunks=\"auto\", as_ref=False, zooms=None):\n    \"\"\"\n    Creates a ZarrNii instance from a NIfTI file. Populates OME-Zarr metadata\n    based on the NIfTI affine matrix.\n\n    Parameters:\n        path (str): Path to the NIfTI file.\n        chunks (str or tuple): Chunk size for dask array (default: \"auto\").\n        as_ref (bool): If True, creates an empty dask array with the correct shape instead of loading data.\n        zooms (list or np.ndarray): Target voxel spacing in xyz (only valid if as_ref=True).\n\n    Returns:\n        ZarrNii: A populated ZarrNii instance.\n\n    Raises:\n        ValueError: If `zooms` is specified when `as_ref=False`.\n    \"\"\"\n    if not as_ref and zooms is not None:\n        raise ValueError(\"`zooms` can only be used when `as_ref=True`.\")\n\n    # Load the NIfTI file and extract metadata\n    nii = nib.load(path)\n    shape = nii.header.get_data_shape()\n    affine = nii.affine\n\n    # Adjust shape and affine if zooms are provided\n    if zooms is not None:\n        in_zooms = np.sqrt(\n            (affine[:3, :3] ** 2).sum(axis=0)\n        )  # Current voxel spacing\n        scaling_factor = in_zooms / zooms\n        new_shape = [\n            int(np.floor(shape[0] * scaling_factor[2])),  # Z\n            int(np.floor(shape[1] * scaling_factor[1])),  # Y\n            int(np.floor(shape[2] * scaling_factor[0])),  # X\n        ]\n        np.fill_diagonal(affine[:3, :3], zooms)\n    else:\n        new_shape = shape\n\n    if as_ref:\n        # Create an empty dask array with the adjusted shape\n        darr = da.empty((1, *new_shape), chunks=chunks, dtype=\"float32\")\n    else:\n        # Load the NIfTI data and convert to a dask array\n        data = np.expand_dims(nii.get_fdata(), axis=0)  # Add a channel dimension\n        darr = da.from_array(data, chunks=chunks)\n\n    # Define axes order and metadata\n    axes_order = \"XYZ\"\n    axes = [\n        {\"name\": \"channel\", \"type\": \"channel\", \"unit\": None},\n        {\"name\": \"x\", \"type\": \"space\", \"unit\": \"millimeter\"},\n        {\"name\": \"y\", \"type\": \"space\", \"unit\": \"millimeter\"},\n        {\"name\": \"z\", \"type\": \"space\", \"unit\": \"millimeter\"},\n    ]\n\n    # Extract coordinate transformations from the affine matrix\n    scale = np.sqrt((affine[:3, :3] ** 2).sum(axis=0))  # Diagonal scales\n    translation = affine[:3, 3]  # Translation vector\n    coordinate_transformations = [\n        {\"type\": \"scale\", \"scale\": [1] + scale.tolist()},  # Add channel scale\n        {\n            \"type\": \"translation\",\n            \"translation\": [0] + translation.tolist(),\n        },  # Add channel translation\n    ]\n\n    # Define basic Omero metadata\n    omero = {\n        \"channels\": [{\"label\": \"Channel-0\"}],  # Placeholder channel information\n        \"rdefs\": {\"model\": \"color\"},\n    }\n\n    # Create and return the ZarrNii instance\n    return cls(\n        darr,\n        affine=AffineTransform.from_array(affine),\n        axes_order=axes_order,\n        axes=axes,\n        coordinate_transformations=coordinate_transformations,\n        omero=omero,\n    )\n</code></pre>"},{"location":"reference/#to_ome_zarr","title":"<code>to_ome_zarr</code>","text":"<p>Save the current ZarrNii instance to an OME-Zarr dataset, always writing axes in ZYX order.</p> <p>Parameters:</p> Name Type Description Default <code>store_or_path</code> <code>str or BaseStore</code> <p>Output path or Zarr store.</p> required <code>max_layer</code> <code>int</code> <p>Maximum number of downsampling layers (default: 4). TODO: update this</p> <code>4</code> <code>scaling_method</code> <code>str</code> <p>Method for downsampling (default: \"itk_bin_shrink\").</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments for <code>ngff_zarr.to_ngff_zarr</code>.</p> <code>{}</code> Source code in <code>zarrnii/core.py</code> <pre><code>    def to_ome_zarr(self, store_or_path, max_layer=4, scaling_method=None,\n                    #\"itk_bin_shrink\",\n                    **kwargs):\n        \"\"\"\n        Save the current ZarrNii instance to an OME-Zarr dataset, always writing\n        axes in ZYX order.\n\n        Parameters:\n            store_or_path (str or zarr.storage.BaseStore): Output path or Zarr store.\n            max_layer (int): Maximum number of downsampling layers (default: 4). TODO: update this\n            scaling_method (str): Method for downsampling (default: \"itk_bin_shrink\").\n            **kwargs: Additional arguments for `ngff_zarr.to_ngff_zarr`.\n        \"\"\"\n\n        # Reorder data if the axes order is XYZ (NIfTI-like)\n        if self.axes_order == \"XYZ\":\n            out_darr = da.moveaxis(\n                self.darr, (0, 1, 2, 3), (0, 3, 2, 1)\n            )  \n            out_affine = self.reorder_affine_xyz_zyx(self.affine.matrix)\n            out_axes = self.axes.reverse()\n        else:\n            out_darr = self.darr\n            out_affine = self.affine.matrix\n            out_axes = self.axes\n\n        # Extract offset and voxel dimensions from the affine matrix\n        offset = out_affine[:3, 3]\n        voxdim = np.sqrt((out_affine[:3, :3] ** 2).sum(axis=0))  # Extract scales\n\n        #TODO: deal with fsspec and zipstores too !\n        # Handle either a path or an existing store\n        if isinstance(store_or_path, str):\n#            store = zarr.storage.FsspecStore.from_url(store_or_path)\n            store = zarr.storage.LocalStore(store_or_path) #FsspecStore.from_url(store_or_path)\n        else:\n            store = store_or_path\n\n\n        ngff_img = nz.to_ngff_image(out_darr,\n                                    dims=['c','z','y','x'],\n                                    scale={'z': voxdim[0],\n                                           'y': voxdim[1],\n                                           'x': voxdim[2]},\n                                    translation={'z': offset[0],\n                                                 'y': offset[1],\n                                                 'x': offset[2]})\n\n\n        scale_factors = [2**i for i in range(1,max_layer)]\n        multiscales= nz.to_multiscales(ngff_img, \n                                       #method=scaling_method, \n#                                       method=nz.Methods.ITK_BIN_SHRINK,\n                                       scale_factors=scale_factors)\n\n        nz.to_ngff_zarr(store_or_path, multiscales, **kwargs)\n\n        #now add orientation metadata\n        group = zarr.open_group(store, mode='r+')\n\n        # Add metadata for orientation\n        group.attrs[\"orientation\"] = affine_to_orientation(\n            out_affine\n        )  # Write current orientation\n</code></pre>"},{"location":"reference/#to_nifti","title":"<code>to_nifti</code>","text":"<p>Convert the current ZarrNii instance to a NIfTI-1 image (Nifti1Image) and optionally save it to a file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Output path for the NIfTI file. If None,                       the function returns the NIfTI object.</p> <code>None</code> <p>Returns:</p> Type Description <p>nib.Nifti1Image: The NIfTI-1 image representation of the ZarrNii instance              if <code>filename</code> is not provided.</p> Notes <ul> <li>Reorders data to XYZ order if the current <code>axes_order</code> is ZYX.</li> <li>Adjusts the affine matrix accordingly to match the reordered data.</li> </ul> Source code in <code>zarrnii/core.py</code> <pre><code>def to_nifti(self, filename=None):\n    \"\"\"\n    Convert the current ZarrNii instance to a NIfTI-1 image (Nifti1Image)\n    and optionally save it to a file.\n\n    Parameters:\n        filename (str, optional): Output path for the NIfTI file. If None,\n                                  the function returns the NIfTI object.\n\n    Returns:\n        nib.Nifti1Image: The NIfTI-1 image representation of the ZarrNii instance\n                         if `filename` is not provided.\n\n    Notes:\n        - Reorders data to XYZ order if the current `axes_order` is ZYX.\n        - Adjusts the affine matrix accordingly to match the reordered data.\n    \"\"\"\n\n    # Reorder data to match NIfTI's expected XYZ order if necessary\n    if self.axes_order == \"ZYX\":\n        data = da.moveaxis(\n            self.darr, (0, 1, 2, 3), (0, 3, 2, 1)\n        ).compute()  # Reorder to XYZ\n        affine = self.reorder_affine_xyz_zyx(\n            self.affine.matrix\n        )  # Reorder affine to match\n    else:\n        data = self.darr.compute()\n        affine = self.affine.matrix  # No reordering needed\n    # Create the NIfTI-1 image\n    nii_img = nib.Nifti1Image(\n        data[0], affine\n    )  # Remove the channel dimension for NIfTI\n\n    # Save the NIfTI file if a filename is provided\n    if filename:\n        nib.save(nii_img, filename)\n    else:\n        return nii_img\n</code></pre>"},{"location":"reference/#downsample","title":"<code>downsample</code>","text":"<p>Downsamples the ZarrNii instance by local mean reduction.</p> <p>Parameters:</p> Name Type Description Default <code>along_x</code> <code>int</code> <p>Downsampling factor along the X-axis (default: 1).</p> <code>1</code> <code>along_y</code> <code>int</code> <p>Downsampling factor along the Y-axis (default: 1).</p> <code>1</code> <code>along_z</code> <code>int</code> <p>Downsampling factor along the Z-axis (default: 1).</p> <code>1</code> <code>level</code> <code>int</code> <p>If specified, calculates x y and z downsampling factors based on the level.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>ZarrNii</code> <p>A new ZarrNii instance with the downsampled data and updated affine.</p> Notes <ul> <li>If <code>level</code> is provided, downsampling factors are calculated as:<ul> <li><code>along_x = along_y = along_z = 2**level</code></li> </ul> </li> <li>Updates the affine matrix to reflect the new voxel size after downsampling.</li> <li>Uses <code>dask.array.coarsen</code> for efficient reduction along specified axes.</li> </ul> Example Source code in <code>zarrnii/core.py</code> <pre><code>def downsample(\n    self, along_x=1, along_y=1, along_z=1, level=None\n):\n    \"\"\"\n    Downsamples the ZarrNii instance by local mean reduction.\n\n    Parameters:\n        along_x (int, optional): Downsampling factor along the X-axis (default: 1).\n        along_y (int, optional): Downsampling factor along the Y-axis (default: 1).\n        along_z (int, optional): Downsampling factor along the Z-axis (default: 1).\n        level (int, optional): If specified, calculates x y and z downsampling factors based on the level.\n\n    Returns:\n        ZarrNii: A new ZarrNii instance with the downsampled data and updated affine.\n\n    Notes:\n        - If `level` is provided, downsampling factors are calculated as:\n            - `along_x = along_y = along_z = 2**level`\n        - Updates the affine matrix to reflect the new voxel size after downsampling.\n        - Uses `dask.array.coarsen` for efficient reduction along specified axes.\n\n    Example:\n        # Downsample by specific factors\n        downsampled_znimg = znimg.downsample(along_x=2, along_y=2, along_z=1)\n\n        # Downsample using a pyramid level\n        downsampled_znimg = znimg.downsample(level=2)\n    \"\"\"\n    # Calculate downsampling factors if level is specified\n    if level is not None:\n        along_x = 2**level\n        along_y = 2**level\n        along_z = 2**level\n\n    # Determine axes mapping based on axes_order\n    if self.axes_order == \"XYZ\":\n        axes = {0: 1, 1: along_x, 2: along_y, 3: along_z}  # (C, X, Y, Z)\n    else:\n        axes = {0: 1, 1: along_z, 2: along_y, 3: along_x}  # (C, Z, Y, X)\n\n    # Perform local mean reduction using coarsen\n    agg_func = np.mean\n    darr_scaled = da.coarsen(agg_func, x=self.darr, axes=axes, trim_excess=True)\n\n    # Update the affine matrix to reflect downsampling\n    scaling_matrix = np.diag((along_x, along_y, along_z, 1))\n    new_affine = AffineTransform.from_array(scaling_matrix @ self.affine.matrix)\n\n    # Create and return a new ZarrNii instance\n    return ZarrNii.from_darr(\n        darr_scaled, affine=new_affine, axes_order=self.axes_order\n    )\n</code></pre>"},{"location":"reference/#zarrnii.ZarrNii.downsample--downsample-by-specific-factors","title":"Downsample by specific factors","text":"<p>downsampled_znimg = znimg.downsample(along_x=2, along_y=2, along_z=1)</p>"},{"location":"reference/#zarrnii.ZarrNii.downsample--downsample-using-a-pyramid-level","title":"Downsample using a pyramid level","text":"<p>downsampled_znimg = znimg.downsample(level=2)</p>"},{"location":"reference/#upsample","title":"<code>upsample</code>","text":"<p>Upsamples the ZarrNii instance using <code>scipy.ndimage.zoom</code>.</p> <p>Parameters:</p> Name Type Description Default <code>along_x</code> <code>int</code> <p>Upsampling factor along the X-axis (default: 1).</p> <code>1</code> <code>along_y</code> <code>int</code> <p>Upsampling factor along the Y-axis (default: 1).</p> <code>1</code> <code>along_z</code> <code>int</code> <p>Upsampling factor along the Z-axis (default: 1).</p> <code>1</code> <code>to_shape</code> <code>tuple</code> <p>Target shape for upsampling. Should include all dimensions                          (e.g., <code>(c, z, y, x)</code> for ZYX or <code>(c, x, y, z)</code> for XYZ).                          If provided, <code>along_x</code>, <code>along_y</code>, and <code>along_z</code> are ignored.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>ZarrNii</code> <p>A new ZarrNii instance with the upsampled data and updated affine.</p> Notes <ul> <li>This method supports both direct scaling via <code>along_*</code> factors or target shape via <code>to_shape</code>.</li> <li>If <code>to_shape</code> is provided, chunk sizes and scaling factors are dynamically calculated.</li> <li>Currently, the method assumes <code>axes_order != 'XYZ'</code> for proper affine scaling.</li> <li>The affine matrix is updated to reflect the new voxel size after upsampling.</li> </ul> Example Source code in <code>zarrnii/core.py</code> <pre><code>def upsample(self, along_x=1, along_y=1, along_z=1, to_shape=None):\n    \"\"\"\n    Upsamples the ZarrNii instance using `scipy.ndimage.zoom`.\n\n    Parameters:\n        along_x (int, optional): Upsampling factor along the X-axis (default: 1).\n        along_y (int, optional): Upsampling factor along the Y-axis (default: 1).\n        along_z (int, optional): Upsampling factor along the Z-axis (default: 1).\n        to_shape (tuple, optional): Target shape for upsampling. Should include all dimensions\n                                     (e.g., `(c, z, y, x)` for ZYX or `(c, x, y, z)` for XYZ).\n                                     If provided, `along_x`, `along_y`, and `along_z` are ignored.\n\n    Returns:\n        ZarrNii: A new ZarrNii instance with the upsampled data and updated affine.\n\n    Notes:\n        - This method supports both direct scaling via `along_*` factors or target shape via `to_shape`.\n        - If `to_shape` is provided, chunk sizes and scaling factors are dynamically calculated.\n        - Currently, the method assumes `axes_order != 'XYZ'` for proper affine scaling.\n        - The affine matrix is updated to reflect the new voxel size after upsampling.\n\n    Example:\n        # Upsample with scaling factors\n        upsampled_znimg = znimg.upsample(along_x=2, along_y=2, along_z=2)\n\n        # Upsample to a specific shape\n        upsampled_znimg = znimg.upsample(to_shape=(1, 256, 256, 256))\n    \"\"\"\n    # Determine scaling and chunks based on input parameters\n    if to_shape is None:\n        if self.axes_order == \"XYZ\":\n            scaling = (1, along_x, along_y, along_z)\n        else:\n            scaling = (1, along_z, along_y, along_x)\n\n        chunks_out = tuple(\n            tuple(c * scale for c in chunks_i)\n            for chunks_i, scale in zip(self.darr.chunks, scaling)\n        )\n    else:\n        chunks_out, scaling = self.__get_upsampled_chunks(to_shape)\n\n    # Define block-wise upsampling function\n    def zoom_blocks(x, block_info=None):\n        \"\"\"\n        Scales blocks to the desired size using `scipy.ndimage.zoom`.\n\n        Parameters:\n            x (np.ndarray): Input block data.\n            block_info (dict, optional): Metadata about the current block.\n\n        Returns:\n            np.ndarray: The upscaled block.\n        \"\"\"\n        # Calculate scaling factors based on input and output chunk shapes\n        scaling = tuple(\n            out_n / in_n\n            for out_n, in_n in zip(block_info[None][\"chunk-shape\"], x.shape)\n        )\n        return zoom(x, scaling, order=1, prefilter=False)\n\n    # Perform block-wise upsampling\n    darr_scaled = da.map_blocks(\n        zoom_blocks, self.darr, dtype=self.darr.dtype, chunks=chunks_out\n    )\n\n    # Update the affine matrix to reflect the new voxel size\n    if self.axes_order == \"XYZ\":\n        scaling_matrix = np.diag(\n            (1 / scaling[1], 1 / scaling[2], 1 / scaling[3], 1)\n        )\n    else:\n        scaling_matrix = np.diag(\n            (1 / scaling[-1], 1 / scaling[-2], 1 / scaling[-3], 1)\n        )\n    new_affine = AffineTransform.from_array(scaling_matrix @ self.affine.matrix)\n\n    # Return a new ZarrNii instance with the upsampled data\n    return ZarrNii.from_darr(\n        darr_scaled.rechunk(), affine=new_affine, axes_order=self.axes_order\n    )\n</code></pre>"},{"location":"reference/#zarrnii.ZarrNii.upsample--upsample-with-scaling-factors","title":"Upsample with scaling factors","text":"<p>upsampled_znimg = znimg.upsample(along_x=2, along_y=2, along_z=2)</p>"},{"location":"reference/#zarrnii.ZarrNii.upsample--upsample-to-a-specific-shape","title":"Upsample to a specific shape","text":"<p>upsampled_znimg = znimg.upsample(to_shape=(1, 256, 256, 256))</p>"},{"location":"reference/#remaining-methods-and-functions","title":"Remaining Methods and Functions","text":"<p>Represents a Zarr-based image with NIfTI compatibility and OME-Zarr metadata.</p> <p>Attributes:</p> Name Type Description <code>darr</code> <code>Array</code> <p>The main dask array holding image data.</p> <code>affine</code> <code>AffineTransform</code> <p>The affine transformation matrix.</p> <code>axes_order</code> <code>str</code> <p>The order of the axes in the data array ('ZYX' or 'XYZ').</p> <code>axes</code> <code>Optional[List[Dict]]</code> <p>Metadata about the axes (from OME-Zarr).</p> <code>coordinate_transformations</code> <code>Optional[List[Dict]]</code> <p>Transformations applied to the data (from OME-Zarr metadata).</p> <code>omero</code> <code>Optional[Dict]</code> <p>Metadata related to visualization and channels (from OME-Zarr).</p> <p>               Bases: <code>Transform</code></p>"},{"location":"reference/#zarrnii.ZarrNii.affine","title":"<code>affine = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/#zarrnii.ZarrNii.axes","title":"<code>axes = field(default=None, metadata={'description': 'Metadata about the axes'})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/#zarrnii.ZarrNii.axes_order","title":"<code>axes_order = 'ZYX'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/#zarrnii.ZarrNii.coordinate_transformations","title":"<code>coordinate_transformations = field(default=None, metadata={'description': 'OME-Zarr coordinate transformations'})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/#zarrnii.ZarrNii.darr","title":"<code>darr</code>  <code>instance-attribute</code>","text":""},{"location":"reference/#zarrnii.ZarrNii.omero","title":"<code>omero = field(default=None, metadata={'description': 'OME-Zarr Omero metadata'})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/#zarrnii.ZarrNii.__get_upsampled_chunks","title":"<code>__get_upsampled_chunks(target_shape, return_scaling=True)</code>","text":"<p>Calculates new chunk sizes for a dask array to match a target shape, while ensuring the chunks sum precisely to the target shape. Optionally, returns the scaling factors for each dimension.</p> <p>This method is useful for upsampling data or ensuring 1:1 correspondence between downsampled and upsampled arrays.</p> <p>Parameters:</p> Name Type Description Default <code>target_shape</code> <code>tuple</code> <p>The desired shape of the array after upsampling.</p> required <code>return_scaling</code> <code>bool</code> <p>Whether to return the scaling factors                              for each dimension (default: True).</p> <code>True</code> <p>Returns:</p> Name Type Description <code>tuple</code> <p>new_chunks (tuple): A tuple of tuples specifying the new chunk sizes                     for each dimension. scaling (list): A list of scaling factors for each dimension                 (only if <code>return_scaling=True</code>).</p> <p>OR</p> <code>tuple</code> <p>new_chunks (tuple): A tuple of tuples specifying the new chunk sizes                     for each dimension (if <code>return_scaling=False</code>).</p> Notes <ul> <li>The scaling factor for each dimension is calculated as:   <code>scaling_factor = target_shape[dim] / original_shape[dim]</code></li> <li>The last chunk in each dimension is adjusted to account for rounding   errors, ensuring the sum of chunks matches the target shape.</li> </ul> Example Source code in <code>zarrnii/core.py</code> <pre><code>def __get_upsampled_chunks(self, target_shape, return_scaling=True):\n    \"\"\"\n    Calculates new chunk sizes for a dask array to match a target shape,\n    while ensuring the chunks sum precisely to the target shape. Optionally,\n    returns the scaling factors for each dimension.\n\n    This method is useful for upsampling data or ensuring 1:1 correspondence\n    between downsampled and upsampled arrays.\n\n    Parameters:\n        target_shape (tuple): The desired shape of the array after upsampling.\n        return_scaling (bool, optional): Whether to return the scaling factors\n                                         for each dimension (default: True).\n\n    Returns:\n        tuple:\n            new_chunks (tuple): A tuple of tuples specifying the new chunk sizes\n                                for each dimension.\n            scaling (list): A list of scaling factors for each dimension\n                            (only if `return_scaling=True`).\n\n        OR\n\n        tuple:\n            new_chunks (tuple): A tuple of tuples specifying the new chunk sizes\n                                for each dimension (if `return_scaling=False`).\n\n    Notes:\n        - The scaling factor for each dimension is calculated as:\n          `scaling_factor = target_shape[dim] / original_shape[dim]`\n        - The last chunk in each dimension is adjusted to account for rounding\n          errors, ensuring the sum of chunks matches the target shape.\n\n    Example:\n        # Calculate upsampled chunks and scaling factors\n        new_chunks, scaling = znimg.__get_upsampled_chunks((256, 256, 256))\n        print(\"New chunks:\", new_chunks)\n        print(\"Scaling factors:\", scaling)\n\n        # Calculate only the new chunks\n        new_chunks = znimg.__get_upsampled_chunks((256, 256, 256), return_scaling=False)\n    \"\"\"\n    new_chunks = []\n    scaling = []\n\n    for dim, (orig_shape, orig_chunks, new_shape) in enumerate(\n        zip(self.darr.shape, self.darr.chunks, target_shape)\n    ):\n        # Calculate the scaling factor for this dimension\n        scaling_factor = new_shape / orig_shape\n\n        # Scale each chunk size and round to get an initial estimate\n        scaled_chunks = [\n            int(round(chunk * scaling_factor)) for chunk in orig_chunks\n        ]\n        total = sum(scaled_chunks)\n\n        # Adjust the chunks to ensure they sum up to the target shape exactly\n        diff = new_shape - total\n        if diff != 0:\n            # Correct rounding errors by adjusting the last chunk size in the dimension\n            scaled_chunks[-1] += diff\n\n        new_chunks.append(tuple(scaled_chunks))\n        scaling.append(scaling_factor)\n\n    if return_scaling:\n        return tuple(new_chunks), scaling\n    else:\n        return tuple(new_chunks)\n</code></pre>"},{"location":"reference/#zarrnii.ZarrNii.__get_upsampled_chunks--calculate-upsampled-chunks-and-scaling-factors","title":"Calculate upsampled chunks and scaling factors","text":"<p>new_chunks, scaling = znimg.__get_upsampled_chunks((256, 256, 256)) print(\"New chunks:\", new_chunks) print(\"Scaling factors:\", scaling)</p>"},{"location":"reference/#zarrnii.ZarrNii.__get_upsampled_chunks--calculate-only-the-new-chunks","title":"Calculate only the new chunks","text":"<p>new_chunks = znimg.__get_upsampled_chunks((256, 256, 256), return_scaling=False)</p>"},{"location":"reference/#zarrnii.ZarrNii.align_affine_to_input_orientation","title":"<code>align_affine_to_input_orientation(affine, orientation)</code>  <code>staticmethod</code>","text":"<p>Reorders and flips the affine matrix to align with the specified input orientation.</p> <p>Parameters:</p> Name Type Description Default <code>affine</code> <code>ndarray</code> <p>Initial affine matrix.</p> required <code>in_orientation</code> <code>str</code> <p>Input orientation (e.g., 'RAS').</p> required <p>Returns:</p> Type Description <p>np.ndarray: Reordered and flipped affine matrix.</p> Source code in <code>zarrnii/core.py</code> <pre><code>@staticmethod\ndef align_affine_to_input_orientation(affine, orientation):\n    \"\"\"\n    Reorders and flips the affine matrix to align with the specified input orientation.\n\n    Parameters:\n        affine (np.ndarray): Initial affine matrix.\n        in_orientation (str): Input orientation (e.g., 'RAS').\n\n    Returns:\n        np.ndarray: Reordered and flipped affine matrix.\n    \"\"\"\n    axis_map = {\"R\": 0, \"L\": 0, \"A\": 1, \"P\": 1, \"S\": 2, \"I\": 2}\n    sign_map = {\"R\": 1, \"L\": -1, \"A\": 1, \"P\": -1, \"S\": 1, \"I\": -1}\n\n    input_axes = [axis_map[ax] for ax in orientation]\n    input_signs = [sign_map[ax] for ax in orientation]\n\n    reordered_affine = np.zeros_like(affine)\n    for i, (axis, sign) in enumerate(zip(input_axes, input_signs)):\n        reordered_affine[i, :3] = sign * affine[axis, :3]\n        reordered_affine[i, 3] = sign * affine[i, 3]\n    reordered_affine[3, :] = affine[3, :]  # Preserve homogeneous row\n\n    return reordered_affine\n</code></pre>"},{"location":"reference/#zarrnii.ZarrNii.apply_transform","title":"<code>apply_transform(*tfms, ref_znimg)</code>","text":"<p>Apply a sequence of transformations to the current ZarrNii instance to align it with the reference ZarrNii instance (<code>ref_znimg</code>).</p> <p>This is a lazy operation and doesn't perform computations until <code>.compute()</code> is called on the returned dask array.</p> <p>Parameters:</p> Name Type Description Default <code>*tfms</code> <p>Transformations to apply. Each transformation should be a    Transform (or subclass) object.</p> <code>()</code> <code>ref_znimg</code> <code>ZarrNii</code> <p>The reference ZarrNii instance to align with.</p> required <p>Returns:</p> Name Type Description <code>ZarrNii</code> <p>A new ZarrNii instance with the transformations applied.</p> Notes <ul> <li>The transformations are applied in the following order:</li> <li>The affine transformation of the reference image.</li> <li>The transformations passed as <code>*tfms</code>.</li> <li>The inverse affine transformation of the current image.</li> <li>The data in the returned ZarrNii is lazily interpolated using   <code>dask.array.map_blocks</code>.</li> </ul> Example <p>transformed_znimg = znimg.apply_transform(     transform1, transform2, ref_znimg=ref_image )</p> Source code in <code>zarrnii/core.py</code> <pre><code>def apply_transform(self, *tfms, ref_znimg):\n    \"\"\"\n    Apply a sequence of transformations to the current ZarrNii instance\n    to align it with the reference ZarrNii instance (`ref_znimg`).\n\n    This is a lazy operation and doesn't perform computations until\n    `.compute()` is called on the returned dask array.\n\n    Parameters:\n        *tfms: Transformations to apply. Each transformation should be a\n               Transform (or subclass) object.\n        ref_znimg (ZarrNii): The reference ZarrNii instance to align with.\n\n    Returns:\n        ZarrNii: A new ZarrNii instance with the transformations applied.\n\n    Notes:\n        - The transformations are applied in the following order:\n          1. The affine transformation of the reference image.\n          2. The transformations passed as `*tfms`.\n          3. The inverse affine transformation of the current image.\n        - The data in the returned ZarrNii is lazily interpolated using\n          `dask.array.map_blocks`.\n\n    Example:\n        transformed_znimg = znimg.apply_transform(\n            transform1, transform2, ref_znimg=ref_image\n        )\n    \"\"\"\n    # Initialize the list of transformations to apply\n    tfms_to_apply = [ref_znimg.affine]  # Start with the reference image affine\n\n    # Append all transformations passed as arguments\n    tfms_to_apply.extend(tfms)\n\n    # Append the inverse of the current image's affine\n    tfms_to_apply.append(self.affine.invert())\n\n    # Create a new ZarrNii instance for the interpolated image\n    interp_znimg = ref_znimg\n\n    # Lazily apply the transformations using dask\n    interp_znimg.darr = da.map_blocks(\n        interp_by_block,  # Function to interpolate each block\n        ref_znimg.darr,  # Reference image data\n        dtype=np.float32,  # Output data type\n        transforms=tfms_to_apply,  # Transformations to apply\n        flo_znimg=self,  # Floating image to align\n    )\n\n    return interp_znimg\n</code></pre>"},{"location":"reference/#zarrnii.ZarrNii.apply_transform_flo_to_ref_indices","title":"<code>apply_transform_flo_to_ref_indices(*tfms, ref_znimg, indices)</code>","text":"<p>Transforms indices from the floating image space to the reference image space by applying a sequence of transformations.</p> <p>Parameters:</p> Name Type Description Default <code>*tfms</code> <p>Transform objects to apply. These can be <code>AffineTransform</code>,    <code>DisplacementTransform</code>, or other subclasses of <code>Transform</code>.</p> <code>()</code> <code>ref_znimg</code> <code>ZarrNii</code> <p>The reference ZarrNii instance defining the target space.</p> required <code>indices</code> <code>ndarray</code> <p>3xN array of indices in the floating image space.</p> required <p>Returns:</p> Type Description <p>np.ndarray: 3xN array of transformed indices in the reference image space.</p> Notes <ul> <li>Indices are treated as vectors in homogeneous coordinates, enabling   transformation via matrix multiplication.</li> <li>Transformations are applied in the following order:</li> <li>The affine transformation of the floating image.</li> <li>The transformations passed as <code>*tfms</code>.</li> <li>The inverse affine transformation of the reference image.</li> </ul> Example <p>transformed_indices = flo_znimg.apply_transform_flo_to_ref_indices(     transform1, transform2, ref_znimg=ref_image, indices=indices_in_flo )</p> Source code in <code>zarrnii/core.py</code> <pre><code>def apply_transform_flo_to_ref_indices(self, *tfms, ref_znimg, indices):\n    \"\"\"\n    Transforms indices from the floating image space to the reference image space\n    by applying a sequence of transformations.\n\n    Parameters:\n        *tfms: Transform objects to apply. These can be `AffineTransform`,\n               `DisplacementTransform`, or other subclasses of `Transform`.\n        ref_znimg (ZarrNii): The reference ZarrNii instance defining the target space.\n        indices (np.ndarray): 3xN array of indices in the floating image space.\n\n    Returns:\n        np.ndarray: 3xN array of transformed indices in the reference image space.\n\n    Notes:\n        - Indices are treated as vectors in homogeneous coordinates, enabling\n          transformation via matrix multiplication.\n        - Transformations are applied in the following order:\n          1. The affine transformation of the floating image.\n          2. The transformations passed as `*tfms`.\n          3. The inverse affine transformation of the reference image.\n\n    Example:\n        transformed_indices = flo_znimg.apply_transform_flo_to_ref_indices(\n            transform1, transform2, ref_znimg=ref_image, indices=indices_in_flo\n        )\n    \"\"\"\n    # Initialize the list of transformations to apply\n    tfms_to_apply = [self.affine]  # Start with the floating image affine\n\n    # Append all provided transformations\n    tfms_to_apply.extend(tfms)\n\n    # Append the inverse affine transformation of the reference image\n    tfms_to_apply.append(ref_znimg.affine.invert())\n\n    # Ensure indices are in homogeneous coordinates (4xN matrix)\n    homog = np.ones((1, indices.shape[1]))\n    xfm_vecs = np.vstack((indices, homog))\n\n    # Sequentially apply transformations\n    for tfm in tfms_to_apply:\n        xfm_vecs = tfm.apply_transform(xfm_vecs)\n\n    # Return the transformed indices in non-homogeneous coordinates\n    return xfm_vecs[:3, :]\n</code></pre>"},{"location":"reference/#zarrnii.ZarrNii.apply_transform_ref_to_flo_indices","title":"<code>apply_transform_ref_to_flo_indices(*tfms, ref_znimg, indices)</code>","text":"<p>Transforms indices from the reference image space to the floating image space by applying a sequence of transformations.</p> <p>Parameters:</p> Name Type Description Default <code>*tfms</code> <p>Transform objects to apply. These can be <code>AffineTransform</code>,    <code>DisplacementTransform</code>, or other subclasses of <code>Transform</code>.</p> <code>()</code> <code>ref_znimg</code> <code>ZarrNii</code> <p>The reference ZarrNii instance defining the source space.</p> required <code>indices</code> <code>ndarray</code> <p>3xN array of indices in the reference space.</p> required <p>Returns:</p> Type Description <p>np.ndarray: 3xN array of transformed indices in the floating image space.</p> Notes <ul> <li>Indices are treated as vectors in homogeneous coordinates, enabling   transformation via matrix multiplication.</li> <li>Transformations are applied in the following order:</li> <li>The affine transformation of the reference image.</li> <li>The transformations passed as <code>*tfms</code>.</li> <li>The inverse affine transformation of the floating image.</li> </ul> Example <p>transformed_indices = flo_znimg.apply_transform_ref_to_flo_indices(     transform1, transform2, ref_znimg=ref_image, indices=indices_in_ref )</p> Source code in <code>zarrnii/core.py</code> <pre><code>def apply_transform_ref_to_flo_indices(self, *tfms, ref_znimg, indices):\n    \"\"\"\n    Transforms indices from the reference image space to the floating image space\n    by applying a sequence of transformations.\n\n    Parameters:\n        *tfms: Transform objects to apply. These can be `AffineTransform`,\n               `DisplacementTransform`, or other subclasses of `Transform`.\n        ref_znimg (ZarrNii): The reference ZarrNii instance defining the source space.\n        indices (np.ndarray): 3xN array of indices in the reference space.\n\n    Returns:\n        np.ndarray: 3xN array of transformed indices in the floating image space.\n\n    Notes:\n        - Indices are treated as vectors in homogeneous coordinates, enabling\n          transformation via matrix multiplication.\n        - Transformations are applied in the following order:\n          1. The affine transformation of the reference image.\n          2. The transformations passed as `*tfms`.\n          3. The inverse affine transformation of the floating image.\n\n    Example:\n        transformed_indices = flo_znimg.apply_transform_ref_to_flo_indices(\n            transform1, transform2, ref_znimg=ref_image, indices=indices_in_ref\n        )\n    \"\"\"\n    # Initialize the list of transformations to apply\n    tfms_to_apply = [ref_znimg.affine]  # Start with the reference image affine\n\n    # Append all provided transformations\n    tfms_to_apply.extend(tfms)\n\n    # Append the inverse affine transformation of the current image\n    tfms_to_apply.append(self.affine.invert())\n\n    # Ensure indices are in homogeneous coordinates (4xN matrix)\n    homog = np.ones((1, indices.shape[1]))\n    xfm_vecs = np.vstack((indices, homog))\n\n    # Sequentially apply transformations\n    for tfm in tfms_to_apply:\n        xfm_vecs = tfm.apply_transform(xfm_vecs)\n\n    # Return the transformed indices in non-homogeneous coordinates\n    return xfm_vecs[:3, :]\n</code></pre>"},{"location":"reference/#zarrnii.ZarrNii.construct_affine","title":"<code>construct_affine(coordinate_transformations, orientation)</code>  <code>staticmethod</code>","text":"<p>Constructs the affine matrix based on OME-Zarr coordinate transformations and adjusts it for the input orientation.</p> <p>Parameters:</p> Name Type Description Default <code>coordinate_transformations</code> <code>list</code> <p>Coordinate transformations from OME-Zarr metadata.</p> required <code>orientation</code> <code>str</code> <p>Input orientation (e.g., 'RAS').</p> required <p>Returns:</p> Type Description <p>np.ndarray: A 4x4 affine matrix.</p> Source code in <code>zarrnii/core.py</code> <pre><code>@staticmethod\ndef construct_affine(coordinate_transformations, orientation):\n    \"\"\"\n    Constructs the affine matrix based on OME-Zarr coordinate transformations\n    and adjusts it for the input orientation.\n\n    Parameters:\n        coordinate_transformations (list): Coordinate transformations from OME-Zarr metadata.\n        orientation (str): Input orientation (e.g., 'RAS').\n\n    Returns:\n        np.ndarray: A 4x4 affine matrix.\n    \"\"\"\n    # Initialize affine as an identity matrix\n    affine = np.eye(4)\n\n    # Parse scales and translations\n    scales = [1.0, 1.0, 1.0]\n    translations = [0.0, 0.0, 0.0]\n\n    for transform in coordinate_transformations:\n        if transform.type == \"scale\":\n            scales = transform.scale[-3:]  # Ignore the channel/time dimension\n        elif transform.type == \"translation\":\n            translations = transform.translation[\n                    -3:\n            ]  # Ignore the channel/time dimension\n\n    # Populate the affine matrix\n    affine[:3, :3] = np.diag(scales)  # Set scaling\n    affine[:3, 3] = translations  # Set translation\n\n    # Reorder the affine matrix for the input orientation\n    return ZarrNii.align_affine_to_input_orientation(affine, orientation)\n</code></pre>"},{"location":"reference/#zarrnii.ZarrNii.crop_with_bounding_box","title":"<code>crop_with_bounding_box(bbox_min, bbox_max, ras_coords=False)</code>","text":"<p>Crops the ZarrNii instance using a bounding box and returns a new cropped instance.</p> <p>Parameters:</p> Name Type Description Default <code>bbox_min</code> <code>tuple</code> <p>Minimum corner of the bounding box (Z, Y, X) in voxel coordinates.              If <code>ras_coords=True</code>, this should be in RAS space.</p> required <code>bbox_max</code> <code>tuple</code> <p>Maximum corner of the bounding box (Z, Y, X) in voxel coordinates.              If <code>ras_coords=True</code>, this should be in RAS space.</p> required <code>ras_coords</code> <code>bool</code> <p>Whether the bounding box coordinates are in RAS space.                If True, they will be converted to voxel coordinates using the affine.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>ZarrNii</code> <p>A new ZarrNii instance representing the cropped subregion.</p> Notes <ul> <li>When <code>ras_coords=True</code>, the bounding box coordinates are transformed from RAS to voxel space   using the inverse of the affine transformation.</li> <li>The affine transformation is updated to reflect the cropped region, ensuring spatial consistency.</li> </ul> Example Source code in <code>zarrnii/core.py</code> <pre><code>def crop_with_bounding_box(self, bbox_min, bbox_max, ras_coords=False):\n    \"\"\"\n    Crops the ZarrNii instance using a bounding box and returns a new cropped instance.\n\n    Parameters:\n        bbox_min (tuple): Minimum corner of the bounding box (Z, Y, X) in voxel coordinates.\n                         If `ras_coords=True`, this should be in RAS space.\n        bbox_max (tuple): Maximum corner of the bounding box (Z, Y, X) in voxel coordinates.\n                         If `ras_coords=True`, this should be in RAS space.\n        ras_coords (bool): Whether the bounding box coordinates are in RAS space.\n                           If True, they will be converted to voxel coordinates using the affine.\n\n    Returns:\n        ZarrNii: A new ZarrNii instance representing the cropped subregion.\n\n    Notes:\n        - When `ras_coords=True`, the bounding box coordinates are transformed from RAS to voxel space\n          using the inverse of the affine transformation.\n        - The affine transformation is updated to reflect the cropped region, ensuring spatial consistency.\n\n    Example:\n        # Define a bounding box in voxel space\n        bbox_min = (10, 20, 30)\n        bbox_max = (50, 60, 70)\n\n        # Crop the ZarrNii instance\n        cropped_znimg = znimg.crop_with_bounding_box(bbox_min, bbox_max)\n\n        # Define a bounding box in RAS space\n        ras_min = (-10, -20, -30)\n        ras_max = (10, 20, 30)\n\n        # Crop using RAS coordinates\n        cropped_znimg_ras = znimg.crop_with_bounding_box(ras_min, ras_max, ras_coords=True)\n    \"\"\"\n    # Convert RAS coordinates to voxel coordinates if needed\n    if ras_coords:\n        bbox_min = np.round(self.affine.invert() @ np.array(bbox_min)).astype(int)\n        bbox_max = np.round(self.affine.invert() @ np.array(bbox_max)).astype(int)\n        bbox_min = tuple(bbox_min[:3].flatten())\n        bbox_max = tuple(bbox_max[:3].flatten())\n\n    # Slice the dask array based on the bounding box\n    darr_cropped = self.darr[\n        :,\n        bbox_min[0] : bbox_max[0],  # Z\n        bbox_min[1] : bbox_max[1],  # Y\n        bbox_min[2] : bbox_max[2],  # X\n    ]\n\n    # Update the affine to reflect the cropped region\n    trans_vox = np.eye(4, 4)\n    trans_vox[:3, 3] = bbox_min  # Translation for the cropped region\n    new_affine = self.affine @ trans_vox\n\n    # Create and return a new ZarrNii instance for the cropped region\n    return ZarrNii.from_darr(\n        darr_cropped, affine=new_affine, axes_order=self.axes_order\n    )\n</code></pre>"},{"location":"reference/#zarrnii.ZarrNii.crop_with_bounding_box--define-a-bounding-box-in-voxel-space","title":"Define a bounding box in voxel space","text":"<p>bbox_min = (10, 20, 30) bbox_max = (50, 60, 70)</p>"},{"location":"reference/#zarrnii.ZarrNii.crop_with_bounding_box--crop-the-zarrnii-instance","title":"Crop the ZarrNii instance","text":"<p>cropped_znimg = znimg.crop_with_bounding_box(bbox_min, bbox_max)</p>"},{"location":"reference/#zarrnii.ZarrNii.crop_with_bounding_box--define-a-bounding-box-in-ras-space","title":"Define a bounding box in RAS space","text":"<p>ras_min = (-10, -20, -30) ras_max = (10, 20, 30)</p>"},{"location":"reference/#zarrnii.ZarrNii.crop_with_bounding_box--crop-using-ras-coordinates","title":"Crop using RAS coordinates","text":"<p>cropped_znimg_ras = znimg.crop_with_bounding_box(ras_min, ras_max, ras_coords=True)</p>"},{"location":"reference/#zarrnii.ZarrNii.divide_by_downsampled","title":"<code>divide_by_downsampled(znimg_ds)</code>","text":"<p>Divides the current dask array by another dask array (<code>znimg_ds</code>), which is assumed to be a downsampled version of the current array.</p> <p>This method upscales the downsampled array to match the resolution of the current array before performing element-wise division.</p> <p>Parameters:</p> Name Type Description Default <code>znimg_ds</code> <code>ZarrNii</code> <p>A ZarrNii instance representing the downsampled array.</p> required <p>Returns:</p> Name Type Description <code>ZarrNii</code> <p>A new ZarrNii instance containing the result of the division.</p> Notes <ul> <li>The chunking of the current array is adjusted to ensure 1:1 correspondence   with the chunks of the downsampled array after upscaling.</li> <li>The division operation is performed block-wise using <code>dask.array.map_blocks</code>.</li> </ul> Example <p>znimg_divided = znimg.divide_by_downsampled(downsampled_znimg) print(\"Result shape:\", znimg_divided.darr.shape)</p> Source code in <code>zarrnii/core.py</code> <pre><code>def divide_by_downsampled(self, znimg_ds):\n    \"\"\"\n    Divides the current dask array by another dask array (`znimg_ds`),\n    which is assumed to be a downsampled version of the current array.\n\n    This method upscales the downsampled array to match the resolution\n    of the current array before performing element-wise division.\n\n    Parameters:\n        znimg_ds (ZarrNii): A ZarrNii instance representing the downsampled array.\n\n    Returns:\n        ZarrNii: A new ZarrNii instance containing the result of the division.\n\n    Notes:\n        - The chunking of the current array is adjusted to ensure 1:1 correspondence\n          with the chunks of the downsampled array after upscaling.\n        - The division operation is performed block-wise using `dask.array.map_blocks`.\n\n    Example:\n        znimg_divided = znimg.divide_by_downsampled(downsampled_znimg)\n        print(\"Result shape:\", znimg_divided.darr.shape)\n    \"\"\"\n    # Calculate upsampled chunks for the downsampled array\n    target_chunks = znimg_ds.__get_upsampled_chunks(\n        self.darr.shape, return_scaling=False\n    )\n\n    # Rechunk the current high-resolution array to match the target chunks\n    darr_rechunk = self.darr.rechunk(chunks=target_chunks)\n\n    # Define the block-wise operation for zooming and division\n    def block_zoom_and_divide_by(x1, x2, block_info=None):\n        \"\"\"\n        Zooms x2 to match the size of x1 and performs element-wise division.\n\n        Parameters:\n            x1 (np.ndarray): High-resolution block from the current array.\n            x2 (np.ndarray): Downsampled block from `znimg_ds`.\n            block_info (dict, optional): Metadata about the current block.\n\n        Returns:\n            np.ndarray: The result of `x1 / zoom(x2, scaling)`.\n        \"\"\"\n        # Calculate the scaling factors for zooming\n        scaling = tuple(n1 / n2 for n1, n2 in zip(x1.shape, x2.shape))\n        return x1 / zoom(x2, scaling, order=1, prefilter=False)\n\n    # Perform block-wise division\n    darr_div = da.map_blocks(\n        block_zoom_and_divide_by,\n        darr_rechunk,\n        znimg_ds.darr,\n        dtype=self.darr.dtype,\n    )\n\n    # Return the result as a new ZarrNii instance\n    return ZarrNii(darr_div, self.affine, self.axes_order)\n</code></pre>"},{"location":"reference/#zarrnii.ZarrNii.downsample","title":"<code>downsample(along_x=1, along_y=1, along_z=1, level=None)</code>","text":"<p>Downsamples the ZarrNii instance by local mean reduction.</p> <p>Parameters:</p> Name Type Description Default <code>along_x</code> <code>int</code> <p>Downsampling factor along the X-axis (default: 1).</p> <code>1</code> <code>along_y</code> <code>int</code> <p>Downsampling factor along the Y-axis (default: 1).</p> <code>1</code> <code>along_z</code> <code>int</code> <p>Downsampling factor along the Z-axis (default: 1).</p> <code>1</code> <code>level</code> <code>int</code> <p>If specified, calculates x y and z downsampling factors based on the level.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>ZarrNii</code> <p>A new ZarrNii instance with the downsampled data and updated affine.</p> Notes <ul> <li>If <code>level</code> is provided, downsampling factors are calculated as:<ul> <li><code>along_x = along_y = along_z = 2**level</code></li> </ul> </li> <li>Updates the affine matrix to reflect the new voxel size after downsampling.</li> <li>Uses <code>dask.array.coarsen</code> for efficient reduction along specified axes.</li> </ul> Example Source code in <code>zarrnii/core.py</code> <pre><code>def downsample(\n    self, along_x=1, along_y=1, along_z=1, level=None\n):\n    \"\"\"\n    Downsamples the ZarrNii instance by local mean reduction.\n\n    Parameters:\n        along_x (int, optional): Downsampling factor along the X-axis (default: 1).\n        along_y (int, optional): Downsampling factor along the Y-axis (default: 1).\n        along_z (int, optional): Downsampling factor along the Z-axis (default: 1).\n        level (int, optional): If specified, calculates x y and z downsampling factors based on the level.\n\n    Returns:\n        ZarrNii: A new ZarrNii instance with the downsampled data and updated affine.\n\n    Notes:\n        - If `level` is provided, downsampling factors are calculated as:\n            - `along_x = along_y = along_z = 2**level`\n        - Updates the affine matrix to reflect the new voxel size after downsampling.\n        - Uses `dask.array.coarsen` for efficient reduction along specified axes.\n\n    Example:\n        # Downsample by specific factors\n        downsampled_znimg = znimg.downsample(along_x=2, along_y=2, along_z=1)\n\n        # Downsample using a pyramid level\n        downsampled_znimg = znimg.downsample(level=2)\n    \"\"\"\n    # Calculate downsampling factors if level is specified\n    if level is not None:\n        along_x = 2**level\n        along_y = 2**level\n        along_z = 2**level\n\n    # Determine axes mapping based on axes_order\n    if self.axes_order == \"XYZ\":\n        axes = {0: 1, 1: along_x, 2: along_y, 3: along_z}  # (C, X, Y, Z)\n    else:\n        axes = {0: 1, 1: along_z, 2: along_y, 3: along_x}  # (C, Z, Y, X)\n\n    # Perform local mean reduction using coarsen\n    agg_func = np.mean\n    darr_scaled = da.coarsen(agg_func, x=self.darr, axes=axes, trim_excess=True)\n\n    # Update the affine matrix to reflect downsampling\n    scaling_matrix = np.diag((along_x, along_y, along_z, 1))\n    new_affine = AffineTransform.from_array(scaling_matrix @ self.affine.matrix)\n\n    # Create and return a new ZarrNii instance\n    return ZarrNii.from_darr(\n        darr_scaled, affine=new_affine, axes_order=self.axes_order\n    )\n</code></pre>"},{"location":"reference/#zarrnii.ZarrNii.downsample--downsample-by-specific-factors","title":"Downsample by specific factors","text":"<p>downsampled_znimg = znimg.downsample(along_x=2, along_y=2, along_z=1)</p>"},{"location":"reference/#zarrnii.ZarrNii.downsample--downsample-using-a-pyramid-level","title":"Downsample using a pyramid level","text":"<p>downsampled_znimg = znimg.downsample(level=2)</p>"},{"location":"reference/#zarrnii.ZarrNii.from_array","title":"<code>from_array(array, affine=None, chunks='auto', orientation='RAS', axes_order='XYZ', axes=None, coordinate_transformations=None, omero=None, spacing=(1, 1, 1), origin=(0, 0, 0))</code>  <code>classmethod</code>","text":"<p>Creates a ZarrNii instance from an existing numpy array.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>ndarray</code> <p>Input numpy array.</p> required <code>affine</code> <code>AffineTransform or ndarray</code> <p>Affine transform to associate with the array. If None, an affine will be created based on the orientation, spacing, and origin.</p> <code>None</code> <code>orientation</code> <code>str</code> <p>Orientation string used to generate an affine matrix (default: \"RAS\").</p> <code>'RAS'</code> <code>chunks</code> <code>str or tuple</code> <p>Chunk size for dask array (default: \"auto\").</p> <code>'auto'</code> <code>axes_order</code> <code>str</code> <p>The axes order of the input array (default: \"ZYX\").</p> <code>'XYZ'</code> <code>axes</code> <code>list</code> <p>Axes metadata for OME-Zarr. If None, default axes are generated.</p> <code>None</code> <code>coordinate_transformations</code> <code>list</code> <p>Coordinate transformations for OME-Zarr metadata.</p> <code>None</code> <code>omero</code> <code>dict</code> <p>Omero metadata for OME-Zarr.</p> <code>None</code> <code>spacing</code> <code>tuple</code> <p>Voxel spacing along each axis (default: (1, 1, 1)).</p> <code>(1, 1, 1)</code> <code>origin</code> <code>tuple</code> <p>Origin point in physical space (default: (0, 0, 0)).</p> <code>(0, 0, 0)</code> <p>Returns:</p> Name Type Description <code>ZarrNii</code> <p>A populated ZarrNii instance.</p> Source code in <code>zarrnii/core.py</code> <pre><code>@classmethod\ndef from_array(\n    cls,\n    array,\n    affine=None,\n    chunks=\"auto\",\n    orientation=\"RAS\",\n    axes_order=\"XYZ\",\n    axes=None,\n    coordinate_transformations=None,\n    omero=None,\n    spacing=(1, 1, 1),\n    origin=(0, 0, 0),\n):\n    \"\"\"\n    Creates a ZarrNii instance from an existing numpy array.\n\n    Parameters:\n        array (np.ndarray): Input numpy array.\n        affine (AffineTransform or np.ndarray, optional): Affine transform to associate with the array.\n            If None, an affine will be created based on the orientation, spacing, and origin.\n        orientation (str, optional): Orientation string used to generate an affine matrix (default: \"RAS\").\n        chunks (str or tuple): Chunk size for dask array (default: \"auto\").\n        axes_order (str): The axes order of the input array (default: \"ZYX\").\n        axes (list, optional): Axes metadata for OME-Zarr. If None, default axes are generated.\n        coordinate_transformations (list, optional): Coordinate transformations for OME-Zarr metadata.\n        omero (dict, optional): Omero metadata for OME-Zarr.\n        spacing (tuple, optional): Voxel spacing along each axis (default: (1, 1, 1)).\n        origin (tuple, optional): Origin point in physical space (default: (0, 0, 0)).\n\n\n    Returns:\n        ZarrNii: A populated ZarrNii instance.\n\n    \"\"\"\n\n    return cls.from_darr(\n        da.from_array(array, chunks=chunks),\n        affine=affine,\n        orientation=orientation,\n        axes_order=axes_order,\n        axes=axes,\n        coordinate_transformations=coordinate_transformations,\n        omero=omero,\n        spacing=spacing,\n        origin=origin,\n    )\n</code></pre>"},{"location":"reference/#zarrnii.ZarrNii.from_darr","title":"<code>from_darr(darr, affine=None, orientation='RAS', axes_order='XYZ', axes=None, coordinate_transformations=None, omero=None, spacing=(1, 1, 1), origin=(0, 0, 0), unit='micrometer')</code>  <code>classmethod</code>","text":"<p>Creates a ZarrNii instance from an existing Dask array.</p> <p>Parameters:</p> Name Type Description Default <code>darr</code> <code>Array</code> <p>Input Dask array.</p> required <code>affine</code> <code>AffineTransform or ndarray</code> <p>Affine transform to associate with the array. If None, an affine will be created based on the orientation, spacing, and origin.</p> <code>None</code> <code>orientation</code> <code>str</code> <p>Orientation string used to generate an affine matrix (default: \"RAS\").</p> <code>'RAS'</code> <code>axes_order</code> <code>str</code> <p>The axes order of the input array (default: \"XYZ\").</p> <code>'XYZ'</code> <code>axes</code> <code>list</code> <p>Axes metadata for OME-Zarr. If None, default axes are generated.</p> <code>None</code> <code>coordinate_transformations</code> <code>list</code> <p>Coordinate transformations for OME-Zarr metadata.</p> <code>None</code> <code>omero</code> <code>dict</code> <p>Omero metadata for OME-Zarr.</p> <code>None</code> <code>spacing</code> <code>tuple</code> <p>Voxel spacing along each axis (default: (1, 1, 1)).</p> <code>(1, 1, 1)</code> <code>origin</code> <code>tuple</code> <p>Origin point in physical space (default: (0, 0, 0)).</p> <code>(0, 0, 0)</code> <code>unit</code> <code>str</code> <p>Units for spatial dimensions (default: micrometer).</p> <code>'micrometer'</code> <p>Returns:</p> Name Type Description <code>ZarrNii</code> <p>A populated ZarrNii instance.</p> Source code in <code>zarrnii/core.py</code> <pre><code>@classmethod\ndef from_darr(\n    cls,\n    darr,\n    affine=None,\n    orientation=\"RAS\",\n    axes_order=\"XYZ\",\n    axes=None,\n    coordinate_transformations=None,\n    omero=None,\n    spacing=(1, 1, 1),\n    origin=(0, 0, 0),\n    unit='micrometer',\n):\n    \"\"\"\n    Creates a ZarrNii instance from an existing Dask array.\n\n    Parameters:\n        darr (da.Array): Input Dask array.\n        affine (AffineTransform or np.ndarray, optional): Affine transform to associate with the array.\n            If None, an affine will be created based on the orientation, spacing, and origin.\n        orientation (str, optional): Orientation string used to generate an affine matrix (default: \"RAS\").\n        axes_order (str): The axes order of the input array (default: \"XYZ\").\n        axes (list, optional): Axes metadata for OME-Zarr. If None, default axes are generated.\n        coordinate_transformations (list, optional): Coordinate transformations for OME-Zarr metadata.\n        omero (dict, optional): Omero metadata for OME-Zarr.\n        spacing (tuple, optional): Voxel spacing along each axis (default: (1, 1, 1)).\n        origin (tuple, optional): Origin point in physical space (default: (0, 0, 0)).\n        unit (str, optional): Units for spatial dimensions (default: micrometer).\n\n    Returns:\n        ZarrNii: A populated ZarrNii instance.\n    \"\"\"\n\n    # Generate affine from orientation if not explicitly provided\n    if affine is None:\n        affine = orientation_to_affine(orientation, spacing, origin)\n\n    # Generate default axes if none are provided\n    if axes is None:\n        axes = [{\"name\": \"c\", \"type\": \"channel\", \"unit\": None}] + [\n            {\"name\": ax, \"type\": \"space\", \"unit\": unit} for ax in axes_order\n        ]\n\n    # Generate default coordinate transformations if none are provided\n    if coordinate_transformations is None:\n        # Derive scale and translation from the affine\n        scale = np.sqrt((affine[:3, :3] ** 2).sum(axis=0))  # Diagonal scales\n        translation = affine[:3, 3]  # Translation vector\n        coordinate_transformations = [\n            {\"type\": \"scale\", \"scale\": [1] + scale.tolist()},  # Add channel scale\n            {\n                \"type\": \"translation\",\n                \"translation\": [0] + translation.tolist(),\n            },  # Add channel translation\n        ]\n\n    # Generate default omero metadata if none is provided\n    if omero is None:\n        omero = {\n            \"channels\": [{\"label\": f\"Channel-{i}\"} for i in range(darr.shape[0])],\n            \"rdefs\": {\"model\": \"color\"},\n        }\n\n    # Create and return the ZarrNii instance\n    return cls(\n        darr,\n        affine=AffineTransform.from_array(affine),\n        axes_order=axes_order,\n        axes=axes,\n        coordinate_transformations=coordinate_transformations,\n        omero=omero,\n    )\n</code></pre>"},{"location":"reference/#zarrnii.ZarrNii.from_nifti","title":"<code>from_nifti(path, chunks='auto', as_ref=False, zooms=None)</code>  <code>classmethod</code>","text":"<p>Creates a ZarrNii instance from a NIfTI file. Populates OME-Zarr metadata based on the NIfTI affine matrix.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the NIfTI file.</p> required <code>chunks</code> <code>str or tuple</code> <p>Chunk size for dask array (default: \"auto\").</p> <code>'auto'</code> <code>as_ref</code> <code>bool</code> <p>If True, creates an empty dask array with the correct shape instead of loading data.</p> <code>False</code> <code>zooms</code> <code>list or ndarray</code> <p>Target voxel spacing in xyz (only valid if as_ref=True).</p> <code>None</code> <p>Returns:</p> Name Type Description <code>ZarrNii</code> <p>A populated ZarrNii instance.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>zooms</code> is specified when <code>as_ref=False</code>.</p> Source code in <code>zarrnii/core.py</code> <pre><code>@classmethod\ndef from_nifti(cls, path, chunks=\"auto\", as_ref=False, zooms=None):\n    \"\"\"\n    Creates a ZarrNii instance from a NIfTI file. Populates OME-Zarr metadata\n    based on the NIfTI affine matrix.\n\n    Parameters:\n        path (str): Path to the NIfTI file.\n        chunks (str or tuple): Chunk size for dask array (default: \"auto\").\n        as_ref (bool): If True, creates an empty dask array with the correct shape instead of loading data.\n        zooms (list or np.ndarray): Target voxel spacing in xyz (only valid if as_ref=True).\n\n    Returns:\n        ZarrNii: A populated ZarrNii instance.\n\n    Raises:\n        ValueError: If `zooms` is specified when `as_ref=False`.\n    \"\"\"\n    if not as_ref and zooms is not None:\n        raise ValueError(\"`zooms` can only be used when `as_ref=True`.\")\n\n    # Load the NIfTI file and extract metadata\n    nii = nib.load(path)\n    shape = nii.header.get_data_shape()\n    affine = nii.affine\n\n    # Adjust shape and affine if zooms are provided\n    if zooms is not None:\n        in_zooms = np.sqrt(\n            (affine[:3, :3] ** 2).sum(axis=0)\n        )  # Current voxel spacing\n        scaling_factor = in_zooms / zooms\n        new_shape = [\n            int(np.floor(shape[0] * scaling_factor[2])),  # Z\n            int(np.floor(shape[1] * scaling_factor[1])),  # Y\n            int(np.floor(shape[2] * scaling_factor[0])),  # X\n        ]\n        np.fill_diagonal(affine[:3, :3], zooms)\n    else:\n        new_shape = shape\n\n    if as_ref:\n        # Create an empty dask array with the adjusted shape\n        darr = da.empty((1, *new_shape), chunks=chunks, dtype=\"float32\")\n    else:\n        # Load the NIfTI data and convert to a dask array\n        data = np.expand_dims(nii.get_fdata(), axis=0)  # Add a channel dimension\n        darr = da.from_array(data, chunks=chunks)\n\n    # Define axes order and metadata\n    axes_order = \"XYZ\"\n    axes = [\n        {\"name\": \"channel\", \"type\": \"channel\", \"unit\": None},\n        {\"name\": \"x\", \"type\": \"space\", \"unit\": \"millimeter\"},\n        {\"name\": \"y\", \"type\": \"space\", \"unit\": \"millimeter\"},\n        {\"name\": \"z\", \"type\": \"space\", \"unit\": \"millimeter\"},\n    ]\n\n    # Extract coordinate transformations from the affine matrix\n    scale = np.sqrt((affine[:3, :3] ** 2).sum(axis=0))  # Diagonal scales\n    translation = affine[:3, 3]  # Translation vector\n    coordinate_transformations = [\n        {\"type\": \"scale\", \"scale\": [1] + scale.tolist()},  # Add channel scale\n        {\n            \"type\": \"translation\",\n            \"translation\": [0] + translation.tolist(),\n        },  # Add channel translation\n    ]\n\n    # Define basic Omero metadata\n    omero = {\n        \"channels\": [{\"label\": \"Channel-0\"}],  # Placeholder channel information\n        \"rdefs\": {\"model\": \"color\"},\n    }\n\n    # Create and return the ZarrNii instance\n    return cls(\n        darr,\n        affine=AffineTransform.from_array(affine),\n        axes_order=axes_order,\n        axes=axes,\n        coordinate_transformations=coordinate_transformations,\n        omero=omero,\n    )\n</code></pre>"},{"location":"reference/#zarrnii.ZarrNii.from_ome_zarr","title":"<code>from_ome_zarr(store_or_path, level=0, channels=None, channel_labels=None, chunks='auto', rechunk=False, storage_options=None, orientation='IPL', as_ref=False, zooms=None)</code>  <code>classmethod</code>","text":"<p>Reads in an OME-Zarr file as a ZarrNii image, optionally as a reference.</p> <p>Parameters:</p> Name Type Description Default <code>store_or_path</code> <code>str</code> <p>Store or path to the OME-Zarr file.</p> required <code>level</code> <code>int</code> <p>Pyramid level to load (default: 0).</p> <code>0</code> <code>channels</code> <code>list</code> <p>Channels to load by index (default: None, loads all channels).</p> <code>None</code> <code>channel_labels</code> <code>list</code> <p>Channels to load by label name (default: None).</p> <code>None</code> <code>chunks</code> <code>str or tuple</code> <p>Chunk size for dask array (default: \"auto\").</p> <code>'auto'</code> <code>rechunk</code> <code>bool</code> <p>Whether to rechunk the data (default: False).</p> <code>False</code> <code>storage_options</code> <code>dict</code> <p>Storage options for Zarr.</p> <code>None</code> <code>orientation</code> <code>str</code> <p>Default input orientation if none is specified in metadata (default: 'IPL').</p> <code>'IPL'</code> <code>as_ref</code> <code>bool</code> <p>If True, creates an empty dask array with the correct shape instead of loading data.</p> <code>False</code> <code>zooms</code> <code>list or ndarray</code> <p>Target voxel spacing in xyz (only valid if as_ref=True).</p> <code>None</code> <p>Returns:</p> Name Type Description <code>ZarrNii</code> <p>A populated ZarrNii instance.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>zooms</code> is specified when <code>as_ref=False</code>.</p> <code>ValueError</code> <p>If both <code>channels</code> and <code>channel_labels</code> are specified.</p> <code>ValueError</code> <p>If <code>channel_labels</code> are specified but no omero metadata is found.</p> <code>ValueError</code> <p>If any specified channel label is not found in omero metadata.</p> Source code in <code>zarrnii/core.py</code> <pre><code>@classmethod\ndef from_ome_zarr(\n    cls,\n    store_or_path,\n    level=0,\n    channels=None,\n    channel_labels=None,\n    chunks=\"auto\",\n    rechunk=False,\n    storage_options=None,\n    orientation=\"IPL\",\n    as_ref=False,\n    zooms=None,\n):\n    \"\"\"\n    Reads in an OME-Zarr file as a ZarrNii image, optionally as a reference.\n\n    Parameters:\n        store_or_path (str): Store or path to the OME-Zarr file.\n        level (int): Pyramid level to load (default: 0).\n        channels (list): Channels to load by index (default: None, loads all channels).\n        channel_labels (list): Channels to load by label name (default: None).\n        chunks (str or tuple): Chunk size for dask array (default: \"auto\").\n        rechunk (bool): Whether to rechunk the data (default: False).\n        storage_options (dict): Storage options for Zarr.\n        orientation (str): Default input orientation if none is specified in metadata (default: 'IPL').\n        as_ref (bool): If True, creates an empty dask array with the correct shape instead of loading data.\n        zooms (list or np.ndarray): Target voxel spacing in xyz (only valid if as_ref=True).\n\n    Returns:\n        ZarrNii: A populated ZarrNii instance.\n\n    Raises:\n        ValueError: If `zooms` is specified when `as_ref=False`.\n        ValueError: If both `channels` and `channel_labels` are specified.\n        ValueError: If `channel_labels` are specified but no omero metadata is found.\n        ValueError: If any specified channel label is not found in omero metadata.\n    \"\"\"\n\n    if not as_ref and zooms is not None:\n        raise ValueError(\"`zooms` can only be used when `as_ref=True`.\")\n\n    if channels is not None and channel_labels is not None:\n        raise ValueError(\"Cannot specify both 'channels' and 'channel_labels'. Use one or the other.\")\n\n    # Determine the level and whether downsampling is required\n    if not as_ref:\n        (\n            level,\n            do_downsample,\n            downsampling_kwargs,\n        ) = cls.get_level_and_downsampling_kwargs(\n            store_or_path, level\n        )\n    else:\n        do_downsample = False\n\n\n    multiscales = nz.from_ngff_zarr(store_or_path)\n\n\n    # Read orientation metadata (default to `orientation` if not present)\n    group = zarr.open_group(store_or_path, mode='r')\n\n    orientation = group.attrs.get(\"orientation\", orientation)\n\n    # Handle channel selection - resolve labels to indices if needed\n    final_omero_metadata = multiscales.metadata.omero  # Default fallback\n    if channel_labels is not None:\n        # Try to get omero metadata from zarr group attributes directly\n        # since ngff-zarr sometimes doesn't load it properly\n        omero_metadata = None\n        if 'multiscales' in group.attrs:\n            multiscales_attrs = group.attrs['multiscales']\n            if isinstance(multiscales_attrs, list) and len(multiscales_attrs) &gt; 0:\n                omero_metadata = multiscales_attrs[0].get('omero')\n\n        if omero_metadata is None:\n            raise ValueError(\"Channel labels were specified but no omero metadata found in the OME-Zarr file.\")\n\n        # Extract channel labels from omero metadata\n        if 'channels' not in omero_metadata:\n            raise ValueError(\"No channel information found in omero metadata.\")\n\n        channel_info = omero_metadata['channels']\n        available_labels = [ch.get('label', '') for ch in channel_info]\n\n        # Resolve channel labels to indices\n        resolved_channels = []\n        for label in channel_labels:\n            try:\n                idx = available_labels.index(label)\n                resolved_channels.append(idx)\n            except ValueError:\n                raise ValueError(f\"Channel label '{label}' not found. Available labels: {available_labels}\")\n\n        channels = resolved_channels\n        final_omero_metadata = omero_metadata  # Use the properly loaded metadata\n    elif 'multiscales' in group.attrs:\n        # Even if channel_labels not specified, try to get proper omero metadata\n        multiscales_attrs = group.attrs['multiscales']\n        if isinstance(multiscales_attrs, list) and len(multiscales_attrs) &gt; 0:\n            group_omero = multiscales_attrs[0].get('omero')\n            if group_omero is not None:\n                final_omero_metadata = group_omero\n\n    # Get axis names\n    axis_names = [axis.name for axis in multiscales.metadata.axes]\n\n    # Determine index of 'c' axis\n    c_index = axis_names.index('c')\n\n    # If no channels specified, load all channels\n    if channels is None:\n        # Get total number of channels from the data shape\n        total_shape = multiscales.images[level].data.shape\n        num_channels = total_shape[c_index]\n        channels = list(range(num_channels))\n\n\n    # Build slices: 0 for 't' (drop it), channels for 'c', slice(None) for others\n    slices = []\n    for i, name in enumerate(axis_names):\n        if name == 't':\n            slices.append(0)  # Drop singleton time axis\n        elif name == 'c':\n            slices.append(channels)  # Select specific channel(s)\n        else:\n            slices.append(slice(None))  # Keep full range\n\n    # Apply the slices\n    darr_base = multiscales.images[level].data[tuple(slices)]\n\n\n    shape = darr_base.shape\n\n    coordinate_transformations = multiscales.metadata.datasets[level].coordinateTransformations\n\n    affine = cls.construct_affine(coordinate_transformations, orientation)\n\n    if zooms is not None:\n        # Handle zoom adjustments\n        in_zooms = np.sqrt(\n            (affine[:3, :3] ** 2).sum(axis=0)\n        )  # Current voxel spacing\n        scaling_factor = in_zooms / zooms\n        new_shape = [\n            shape[0],\n            int(np.floor(shape[1] * scaling_factor[2])),  # Z\n            int(np.floor(shape[2] * scaling_factor[1])),  # Y\n            int(np.floor(shape[3] * scaling_factor[0])),  # X\n        ]\n        np.fill_diagonal(affine[:3, :3], zooms)\n    else:\n        new_shape = shape\n\n    # we want to downsample *before* we rechunk\n\n    if as_ref:\n        # Create an empty array with the updated shape\n        darr = da.empty(new_shape, chunks=chunks, dtype=darr_base.dtype)\n    else:\n        darr = darr_base\n\n    znimg = cls(\n        darr,\n        affine=AffineTransform.from_array(affine),\n        axes_order=\"ZYX\",\n        axes=multiscales.metadata.axes,\n        coordinate_transformations=coordinate_transformations,\n        omero=final_omero_metadata, \n    )\n\n    if do_downsample:\n        znimg = znimg.downsample(**downsampling_kwargs)\n\n    if rechunk:\n        znimg.darr = znimg.darr.rechunk(chunks)\n\n    return znimg\n</code></pre>"},{"location":"reference/#zarrnii.ZarrNii.get_bounded_subregion","title":"<code>get_bounded_subregion(points)</code>","text":"<p>Extracts a bounded subregion of the dask array containing the specified points, along with the grid points for interpolation.</p> <p>If the points extend beyond the domain of the dask array, the extent is capped at the boundaries. If all points are outside the domain, the function returns <code>(None, None)</code>.</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>ndarray</code> <p>Nx3 or Nx4 array of coordinates in the array's space.                  If Nx4, the last column is assumed to be the homogeneous                  coordinate and is ignored.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <p>grid_points (tuple): A tuple of three 1D arrays representing the grid                      points along each axis (X, Y, Z) in the subregion. subvol (np.ndarray or None): The extracted subregion as a NumPy array.                              Returns <code>None</code> if all points are outside                              the array domain.</p> Notes <ul> <li>The function uses <code>compute()</code> on the dask array to immediately load the   subregion, as Dask doesn't support the type of indexing required for   interpolation.</li> <li>A padding of 1 voxel is applied around the extent of the points.</li> </ul> Example <p>grid_points, subvol = znimg.get_bounded_subregion(points) if subvol is not None:     print(\"Subvolume shape:\", subvol.shape)</p> Source code in <code>zarrnii/core.py</code> <pre><code>def get_bounded_subregion(self, points: np.ndarray):\n    \"\"\"\n    Extracts a bounded subregion of the dask array containing the specified points,\n    along with the grid points for interpolation.\n\n    If the points extend beyond the domain of the dask array, the extent is capped\n    at the boundaries. If all points are outside the domain, the function returns\n    `(None, None)`.\n\n    Parameters:\n        points (np.ndarray): Nx3 or Nx4 array of coordinates in the array's space.\n                             If Nx4, the last column is assumed to be the homogeneous\n                             coordinate and is ignored.\n\n    Returns:\n        tuple:\n            grid_points (tuple): A tuple of three 1D arrays representing the grid\n                                 points along each axis (X, Y, Z) in the subregion.\n            subvol (np.ndarray or None): The extracted subregion as a NumPy array.\n                                         Returns `None` if all points are outside\n                                         the array domain.\n\n    Notes:\n        - The function uses `compute()` on the dask array to immediately load the\n          subregion, as Dask doesn't support the type of indexing required for\n          interpolation.\n        - A padding of 1 voxel is applied around the extent of the points.\n\n    Example:\n        grid_points, subvol = znimg.get_bounded_subregion(points)\n        if subvol is not None:\n            print(\"Subvolume shape:\", subvol.shape)\n    \"\"\"\n    pad = 1  # Padding around the extent of the points\n\n    # Compute the extent of the points in the array's coordinate space\n    min_extent = np.floor(points.min(axis=1)[:3] - pad).astype(\"int\")\n    max_extent = np.ceil(points.max(axis=1)[:3] + pad).astype(\"int\")\n\n    # Clip the extents to ensure they stay within the bounds of the array\n    clip_min = np.zeros_like(min_extent)\n    clip_max = np.array(self.darr.shape[-3:])  # Z, Y, X dimensions\n\n    min_extent = np.clip(min_extent, clip_min, clip_max)\n    max_extent = np.clip(max_extent, clip_min, clip_max)\n\n    # Check if all points are outside the domain\n    if np.any(max_extent &lt;= min_extent):\n        return None, None\n\n    # Extract the subvolume using the computed extents\n    subvol = self.darr[\n        :,\n        min_extent[0] : max_extent[0],\n        min_extent[1] : max_extent[1],\n        min_extent[2] : max_extent[2],\n    ].compute()\n\n    # Generate grid points for interpolation\n    grid_points = (\n        np.arange(min_extent[0], max_extent[0]),  # Z\n        np.arange(min_extent[1], max_extent[1]),  # Y\n        np.arange(min_extent[2], max_extent[2]),  # X\n    )\n\n    return grid_points, subvol\n</code></pre>"},{"location":"reference/#zarrnii.ZarrNii.get_bounding_box_around_label","title":"<code>get_bounding_box_around_label(label_number, padding=0, ras_coords=False)</code>","text":"<p>Calculates the bounding box around a given label in the ZarrNii instance.</p> <p>Parameters:</p> Name Type Description Default <code>label_number</code> <code>int</code> <p>The label value for which the bounding box is computed.</p> required <code>padding</code> <code>int</code> <p>Extra padding added around the bounding box in voxel units (default: 0).</p> <code>0</code> <code>ras_coords</code> <code>bool</code> <p>If True, returns the bounding box coordinates in RAS space.                          Otherwise, returns voxel coordinates (default: False).</p> <code>False</code> <p>Returns:</p> Name Type Description <code>tuple</code> <p>bbox_min (np.ndarray): Minimum corner of the bounding box (Z, Y, X) as a (3, 1) array. bbox_max (np.ndarray): Maximum corner of the bounding box (Z, Y, X) as a (3, 1) array.</p> Notes <ul> <li>The function uses <code>da.argwhere</code> to locate the indices of the specified label lazily.</li> <li>Padding is added symmetrically around the bounding box, and the result is clipped to   ensure it remains within the array bounds.</li> <li>If <code>ras_coords=True</code>, the bounding box coordinates are transformed to RAS space using   the affine transformation.</li> </ul> Example Source code in <code>zarrnii/core.py</code> <pre><code>def get_bounding_box_around_label(self, label_number, padding=0, ras_coords=False):\n    \"\"\"\n    Calculates the bounding box around a given label in the ZarrNii instance.\n\n    Parameters:\n        label_number (int): The label value for which the bounding box is computed.\n        padding (int, optional): Extra padding added around the bounding box in voxel units (default: 0).\n        ras_coords (bool, optional): If True, returns the bounding box coordinates in RAS space.\n                                     Otherwise, returns voxel coordinates (default: False).\n\n    Returns:\n        tuple:\n            bbox_min (np.ndarray): Minimum corner of the bounding box (Z, Y, X) as a (3, 1) array.\n            bbox_max (np.ndarray): Maximum corner of the bounding box (Z, Y, X) as a (3, 1) array.\n\n    Notes:\n        - The function uses `da.argwhere` to locate the indices of the specified label lazily.\n        - Padding is added symmetrically around the bounding box, and the result is clipped to\n          ensure it remains within the array bounds.\n        - If `ras_coords=True`, the bounding box coordinates are transformed to RAS space using\n          the affine transformation.\n\n    Example:\n        # Compute bounding box for label 1 with 5-voxel padding\n        bbox_min, bbox_max = znimg.get_bounding_box_around_label(1, padding=5)\n\n        # Get the bounding box in RAS space\n        bbox_min_ras, bbox_max_ras = znimg.get_bounding_box_around_label(1, padding=5, ras_coords=True)\n    \"\"\"\n    # Locate the indices of the specified label\n    indices = da.argwhere(self.darr == label_number).compute()\n\n    if indices.size == 0:\n        raise ValueError(f\"Label {label_number} not found in the array.\")\n\n    # Compute the minimum and maximum extents in each dimension\n    bbox_min = (\n        indices.min(axis=0).reshape((4, 1))[1:] - padding\n    )  # Exclude channel axis\n    bbox_max = indices.max(axis=0).reshape((4, 1))[1:] + 1 + padding\n\n    # Clip the extents to ensure they stay within bounds\n    bbox_min = np.clip(bbox_min, 0, np.array(self.darr.shape[1:]).reshape(3, 1))\n    bbox_max = np.clip(bbox_max, 0, np.array(self.darr.shape[1:]).reshape(3, 1))\n\n    # Convert to RAS coordinates if requested\n    if ras_coords:\n        bbox_min = self.affine @ bbox_min\n        bbox_max = self.affine @ bbox_max\n\n    return bbox_min, bbox_max\n</code></pre>"},{"location":"reference/#zarrnii.ZarrNii.get_bounding_box_around_label--compute-bounding-box-for-label-1-with-5-voxel-padding","title":"Compute bounding box for label 1 with 5-voxel padding","text":"<p>bbox_min, bbox_max = znimg.get_bounding_box_around_label(1, padding=5)</p>"},{"location":"reference/#zarrnii.ZarrNii.get_bounding_box_around_label--get-the-bounding-box-in-ras-space","title":"Get the bounding box in RAS space","text":"<p>bbox_min_ras, bbox_max_ras = znimg.get_bounding_box_around_label(1, padding=5, ras_coords=True)</p>"},{"location":"reference/#zarrnii.ZarrNii.get_level_and_downsampling_kwargs","title":"<code>get_level_and_downsampling_kwargs(ome_zarr_path, level)</code>  <code>staticmethod</code>","text":"<p>Determines the appropriate pyramid level and additional downsampling factors for an OME-Zarr dataset.</p> <p>Parameters:</p> Name Type Description Default <code>ome_zarr_path</code> <code>str or MutableMapping</code> <p>Path to the OME-Zarr dataset or a <code>MutableMapping</code> store.</p> required <code>level</code> <code>int</code> <p>Desired downsampling level.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <ul> <li>level (int): The selected pyramid level (capped by the maximum level).</li> <li>do_downsample (bool): Whether additional downsampling is required.</li> <li>downsampling_kwargs (dict): Factors for downsampling along X, Y, and Z.</li> </ul> Notes <ul> <li>If the requested level exceeds the available pyramid levels, the function calculates   additional downsampling factors</li> </ul> Source code in <code>zarrnii/core.py</code> <pre><code>@staticmethod\ndef get_level_and_downsampling_kwargs(\n    ome_zarr_path, level\n):\n    \"\"\"\n    Determines the appropriate pyramid level and additional downsampling factors for an OME-Zarr dataset.\n\n    Parameters:\n        ome_zarr_path (str or MutableMapping): Path to the OME-Zarr dataset or a `MutableMapping` store.\n        level (int): Desired downsampling level.\n\n    Returns:\n        tuple:\n            - level (int): The selected pyramid level (capped by the maximum level).\n            - do_downsample (bool): Whether additional downsampling is required.\n            - downsampling_kwargs (dict): Factors for downsampling along X, Y, and Z.\n\n    Notes:\n        - If the requested level exceeds the available pyramid levels, the function calculates\n          additional downsampling factors\n    \"\"\"\n    max_level = ZarrNii.get_max_level(\n        ome_zarr_path        )\n\n    # Determine the pyramid level and additional downsampling factors\n    if level &gt; max_level:  # Requested level exceeds pyramid levels\n        level_ds = level - max_level\n        level = max_level\n    else:\n        level_ds = 0\n\n\n    # Determine if additional downsampling is needed\n    do_downsample = level_ds &gt; 0\n\n    # Return the level, downsampling flag, and downsampling parameters\n    return (\n        level,\n        do_downsample,\n        {\n            \"along_x\": 2**level_ds,\n            \"along_y\": 2**level_ds,\n            \"along_z\": 2**level_ds,\n        },\n    )\n</code></pre>"},{"location":"reference/#zarrnii.ZarrNii.get_max_level","title":"<code>get_max_level(path)</code>  <code>staticmethod</code>","text":"<p>Retrieves the maximum level of multiscale downsampling in an OME-Zarr dataset.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str or MutableMapping</code> <p>Path to the OME-Zarr dataset or a <code>MutableMapping</code> store.</p> required <code>storage_options</code> <code>dict</code> <p>Storage options for accessing remote or custom storage.</p> required <p>Returns:</p> Name Type Description <code>int</code> <p>The maximum level of multiscale downsampling (zero-based index).</p> <code>None</code> <p>If no multiscale levels are found.</p> Notes <ul> <li>The function assumes that the Zarr dataset follows the OME-Zarr specification   with multiscale metadata.</li> </ul> Source code in <code>zarrnii/core.py</code> <pre><code>@staticmethod\ndef get_max_level(path):\n    \"\"\"\n    Retrieves the maximum level of multiscale downsampling in an OME-Zarr dataset.\n\n    Parameters:\n        path (str or MutableMapping): Path to the OME-Zarr dataset or a `MutableMapping` store.\n        storage_options (dict, optional): Storage options for accessing remote or custom storage.\n\n    Returns:\n        int: The maximum level of multiscale downsampling (zero-based index).\n        None: If no multiscale levels are found.\n\n    Notes:\n        - The function assumes that the Zarr dataset follows the OME-Zarr specification\n          with multiscale metadata.\n    \"\"\"\n    multiscales = nz.from_ngff_zarr(path)\n    return len(multiscales.images)-1\n</code></pre>"},{"location":"reference/#zarrnii.ZarrNii.get_orientation","title":"<code>get_orientation()</code>","text":"<p>Get the anatomical orientation of the dataset based on its affine transformation.</p> <p>This function determines the orientation string (e.g., 'RAS', 'LPI') of the dataset by analyzing the affine transformation matrix.</p> <p>Returns:</p> Name Type Description <code>str</code> <p>The orientation string corresponding to the dataset's affine transformation.</p> Source code in <code>zarrnii/core.py</code> <pre><code>def get_orientation(self):\n    \"\"\"\n    Get the anatomical orientation of the dataset based on its affine transformation.\n\n    This function determines the orientation string (e.g., 'RAS', 'LPI') of the dataset\n    by analyzing the affine transformation matrix.\n\n    Returns:\n        str: The orientation string corresponding to the dataset's affine transformation.\n    \"\"\"\n    return affine_to_orientation(self.affine)\n</code></pre>"},{"location":"reference/#zarrnii.ZarrNii.get_origin","title":"<code>get_origin(axes_order='ZYX')</code>","text":"<p>Get the origin (translation) from the affine matrix, with optional reordering based on axis order.</p> <p>The origin is represented as the translation component in the affine matrix (the last column). If the affine matrix's axis order is different from the provided <code>axes_order</code>, the matrix will be reordered accordingly before extracting the origin.</p> <p>axes_order : str, optional     The desired order of axes (e.g., 'ZYX', 'XYZ'). The default is 'ZYX'. If the current affine     matrix has a different axis order, it will be reordered to match this.</p> <p>ndarray     A 3-element array representing the translation (origin) in world coordinates.</p> <p>Notes: If the affine's axis order is already the same as <code>axes_order</code>, no reordering will be performed.</p> Source code in <code>zarrnii/core.py</code> <pre><code>def get_origin(self, axes_order=\"ZYX\"):\n    \"\"\"\n    Get the origin (translation) from the affine matrix, with optional reordering based on axis order.\n\n    The origin is represented as the translation component in the affine matrix (the last column).\n    If the affine matrix's axis order is different from the provided `axes_order`, the matrix will\n    be reordered accordingly before extracting the origin.\n\n    Parameters:\n    axes_order : str, optional\n        The desired order of axes (e.g., 'ZYX', 'XYZ'). The default is 'ZYX'. If the current affine\n        matrix has a different axis order, it will be reordered to match this.\n\n    Returns:\n    ndarray\n        A 3-element array representing the translation (origin) in world coordinates.\n\n    Notes:\n    If the affine's axis order is already the same as `axes_order`, no reordering will be performed.\n    \"\"\"\n    if axes_order == self.axes_order:\n        affine = self.affine\n    else:\n        affine = self.reorder_affine_xyz_zyx(self.affine)\n\n    return affine[:3, 3]\n</code></pre>"},{"location":"reference/#zarrnii.ZarrNii.get_zooms","title":"<code>get_zooms(axes_order='ZYX')</code>","text":"<p>Get the voxel spacing (zoom factors) from the affine matrix, with optional reordering based on axis order.</p> <p>The zoom factors are derived from the diagonal elements of the upper-left 3x3 part of the affine matrix, representing the voxel spacing along each axis. If the affine matrix's axis order is different from the provided <code>axes_order</code>, the matrix will be reordered accordingly before extracting the zoom factors.</p> <p>axes_order : str, optional     The desired order of axes (e.g., 'ZYX', 'XYZ'). The default is 'ZYX'. If the current affine     matrix has a different axis order, it will be reordered to match this.</p> <p>ndarray     A 3-element array representing the voxel spacing in each dimension (x, y, z).</p> <p>Notes: If the affine's axis order is already the same as <code>axes_order</code>, no reordering will be performed.</p> Source code in <code>zarrnii/core.py</code> <pre><code>def get_zooms(self, axes_order=\"ZYX\"):\n    \"\"\"\n    Get the voxel spacing (zoom factors) from the affine matrix, with optional reordering based on axis order.\n\n    The zoom factors are derived from the diagonal elements of the upper-left 3x3 part of the affine\n    matrix, representing the voxel spacing along each axis. If the affine matrix's axis order is\n    different from the provided `axes_order`, the matrix will be reordered accordingly before extracting\n    the zoom factors.\n\n    Parameters:\n    axes_order : str, optional\n        The desired order of axes (e.g., 'ZYX', 'XYZ'). The default is 'ZYX'. If the current affine\n        matrix has a different axis order, it will be reordered to match this.\n\n    Returns:\n    ndarray\n        A 3-element array representing the voxel spacing in each dimension (x, y, z).\n\n    Notes:\n    If the affine's axis order is already the same as `axes_order`, no reordering will be performed.\n    \"\"\"\n    if axes_order == self.axes_order:\n        affine = self.affine\n    else:\n        affine = self.reorder_affine_xyz_zyx(self.affine)\n\n    return np.sqrt((affine[:3, :3] ** 2).sum(axis=0))  # Extract scales\n</code></pre>"},{"location":"reference/#zarrnii.ZarrNii.reorder_affine_xyz_zyx","title":"<code>reorder_affine_xyz_zyx(affine)</code>  <code>staticmethod</code>","text":"<p>Reorders the affine matrix from ZYX to XYZ axes order and adjusts the translation.</p> <p>Parameters:</p> Name Type Description Default <code>affine</code> <code>ndarray</code> <p>Affine matrix in ZYX order.</p> required <p>Returns:</p> Type Description <p>np.ndarray: Affine matrix reordered to XYZ order.</p> Source code in <code>zarrnii/core.py</code> <pre><code>@staticmethod\ndef reorder_affine_xyz_zyx(affine):\n    \"\"\"\n    Reorders the affine matrix from ZYX to XYZ axes order and adjusts the translation.\n\n    Parameters:\n        affine (np.ndarray): Affine matrix in ZYX order.\n\n    Returns:\n        np.ndarray: Affine matrix reordered to XYZ order.\n    \"\"\"\n    # Reordering matrix to go from ZYX to XYZ\n    reorder_xfm = np.array(\n        [\n            [0, 0, 1, 0],  # Z -&gt; X\n            [0, 1, 0, 0],  # Y -&gt; Y\n            [1, 0, 0, 0],  # X -&gt; Z\n            [0, 0, 0, 1],  # Homogeneous row\n        ]\n    )\n\n    # Apply reordering to the affine matrix\n    affine_reordered = affine @ reorder_xfm\n\n    # Adjust translation (last column)\n    translation_zyx = affine[:3, 3]\n    reorder_perm = [2, 1, 0]  # Map ZYX -&gt; XYZ\n    translation_xyz = translation_zyx[reorder_perm]\n\n    # Update reordered affine with adjusted translation\n    affine_reordered[:3, 3] = translation_xyz\n    return affine_reordered\n</code></pre>"},{"location":"reference/#zarrnii.ZarrNii.to_nifti","title":"<code>to_nifti(filename=None)</code>","text":"<p>Convert the current ZarrNii instance to a NIfTI-1 image (Nifti1Image) and optionally save it to a file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Output path for the NIfTI file. If None,                       the function returns the NIfTI object.</p> <code>None</code> <p>Returns:</p> Type Description <p>nib.Nifti1Image: The NIfTI-1 image representation of the ZarrNii instance              if <code>filename</code> is not provided.</p> Notes <ul> <li>Reorders data to XYZ order if the current <code>axes_order</code> is ZYX.</li> <li>Adjusts the affine matrix accordingly to match the reordered data.</li> </ul> Source code in <code>zarrnii/core.py</code> <pre><code>def to_nifti(self, filename=None):\n    \"\"\"\n    Convert the current ZarrNii instance to a NIfTI-1 image (Nifti1Image)\n    and optionally save it to a file.\n\n    Parameters:\n        filename (str, optional): Output path for the NIfTI file. If None,\n                                  the function returns the NIfTI object.\n\n    Returns:\n        nib.Nifti1Image: The NIfTI-1 image representation of the ZarrNii instance\n                         if `filename` is not provided.\n\n    Notes:\n        - Reorders data to XYZ order if the current `axes_order` is ZYX.\n        - Adjusts the affine matrix accordingly to match the reordered data.\n    \"\"\"\n\n    # Reorder data to match NIfTI's expected XYZ order if necessary\n    if self.axes_order == \"ZYX\":\n        data = da.moveaxis(\n            self.darr, (0, 1, 2, 3), (0, 3, 2, 1)\n        ).compute()  # Reorder to XYZ\n        affine = self.reorder_affine_xyz_zyx(\n            self.affine.matrix\n        )  # Reorder affine to match\n    else:\n        data = self.darr.compute()\n        affine = self.affine.matrix  # No reordering needed\n    # Create the NIfTI-1 image\n    nii_img = nib.Nifti1Image(\n        data[0], affine\n    )  # Remove the channel dimension for NIfTI\n\n    # Save the NIfTI file if a filename is provided\n    if filename:\n        nib.save(nii_img, filename)\n    else:\n        return nii_img\n</code></pre>"},{"location":"reference/#zarrnii.ZarrNii.to_ome_zarr","title":"<code>to_ome_zarr(store_or_path, max_layer=4, scaling_method=None, **kwargs)</code>","text":"<p>Save the current ZarrNii instance to an OME-Zarr dataset, always writing axes in ZYX order.</p> <p>Parameters:</p> Name Type Description Default <code>store_or_path</code> <code>str or BaseStore</code> <p>Output path or Zarr store.</p> required <code>max_layer</code> <code>int</code> <p>Maximum number of downsampling layers (default: 4). TODO: update this</p> <code>4</code> <code>scaling_method</code> <code>str</code> <p>Method for downsampling (default: \"itk_bin_shrink\").</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments for <code>ngff_zarr.to_ngff_zarr</code>.</p> <code>{}</code> Source code in <code>zarrnii/core.py</code> <pre><code>    def to_ome_zarr(self, store_or_path, max_layer=4, scaling_method=None,\n                    #\"itk_bin_shrink\",\n                    **kwargs):\n        \"\"\"\n        Save the current ZarrNii instance to an OME-Zarr dataset, always writing\n        axes in ZYX order.\n\n        Parameters:\n            store_or_path (str or zarr.storage.BaseStore): Output path or Zarr store.\n            max_layer (int): Maximum number of downsampling layers (default: 4). TODO: update this\n            scaling_method (str): Method for downsampling (default: \"itk_bin_shrink\").\n            **kwargs: Additional arguments for `ngff_zarr.to_ngff_zarr`.\n        \"\"\"\n\n        # Reorder data if the axes order is XYZ (NIfTI-like)\n        if self.axes_order == \"XYZ\":\n            out_darr = da.moveaxis(\n                self.darr, (0, 1, 2, 3), (0, 3, 2, 1)\n            )  \n            out_affine = self.reorder_affine_xyz_zyx(self.affine.matrix)\n            out_axes = self.axes.reverse()\n        else:\n            out_darr = self.darr\n            out_affine = self.affine.matrix\n            out_axes = self.axes\n\n        # Extract offset and voxel dimensions from the affine matrix\n        offset = out_affine[:3, 3]\n        voxdim = np.sqrt((out_affine[:3, :3] ** 2).sum(axis=0))  # Extract scales\n\n        #TODO: deal with fsspec and zipstores too !\n        # Handle either a path or an existing store\n        if isinstance(store_or_path, str):\n#            store = zarr.storage.FsspecStore.from_url(store_or_path)\n            store = zarr.storage.LocalStore(store_or_path) #FsspecStore.from_url(store_or_path)\n        else:\n            store = store_or_path\n\n\n        ngff_img = nz.to_ngff_image(out_darr,\n                                    dims=['c','z','y','x'],\n                                    scale={'z': voxdim[0],\n                                           'y': voxdim[1],\n                                           'x': voxdim[2]},\n                                    translation={'z': offset[0],\n                                                 'y': offset[1],\n                                                 'x': offset[2]})\n\n\n        scale_factors = [2**i for i in range(1,max_layer)]\n        multiscales= nz.to_multiscales(ngff_img, \n                                       #method=scaling_method, \n#                                       method=nz.Methods.ITK_BIN_SHRINK,\n                                       scale_factors=scale_factors)\n\n        nz.to_ngff_zarr(store_or_path, multiscales, **kwargs)\n\n        #now add orientation metadata\n        group = zarr.open_group(store, mode='r+')\n\n        # Add metadata for orientation\n        group.attrs[\"orientation\"] = affine_to_orientation(\n            out_affine\n        )  # Write current orientation\n</code></pre>"},{"location":"reference/#zarrnii.ZarrNii.upsample","title":"<code>upsample(along_x=1, along_y=1, along_z=1, to_shape=None)</code>","text":"<p>Upsamples the ZarrNii instance using <code>scipy.ndimage.zoom</code>.</p> <p>Parameters:</p> Name Type Description Default <code>along_x</code> <code>int</code> <p>Upsampling factor along the X-axis (default: 1).</p> <code>1</code> <code>along_y</code> <code>int</code> <p>Upsampling factor along the Y-axis (default: 1).</p> <code>1</code> <code>along_z</code> <code>int</code> <p>Upsampling factor along the Z-axis (default: 1).</p> <code>1</code> <code>to_shape</code> <code>tuple</code> <p>Target shape for upsampling. Should include all dimensions                          (e.g., <code>(c, z, y, x)</code> for ZYX or <code>(c, x, y, z)</code> for XYZ).                          If provided, <code>along_x</code>, <code>along_y</code>, and <code>along_z</code> are ignored.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>ZarrNii</code> <p>A new ZarrNii instance with the upsampled data and updated affine.</p> Notes <ul> <li>This method supports both direct scaling via <code>along_*</code> factors or target shape via <code>to_shape</code>.</li> <li>If <code>to_shape</code> is provided, chunk sizes and scaling factors are dynamically calculated.</li> <li>Currently, the method assumes <code>axes_order != 'XYZ'</code> for proper affine scaling.</li> <li>The affine matrix is updated to reflect the new voxel size after upsampling.</li> </ul> Example Source code in <code>zarrnii/core.py</code> <pre><code>def upsample(self, along_x=1, along_y=1, along_z=1, to_shape=None):\n    \"\"\"\n    Upsamples the ZarrNii instance using `scipy.ndimage.zoom`.\n\n    Parameters:\n        along_x (int, optional): Upsampling factor along the X-axis (default: 1).\n        along_y (int, optional): Upsampling factor along the Y-axis (default: 1).\n        along_z (int, optional): Upsampling factor along the Z-axis (default: 1).\n        to_shape (tuple, optional): Target shape for upsampling. Should include all dimensions\n                                     (e.g., `(c, z, y, x)` for ZYX or `(c, x, y, z)` for XYZ).\n                                     If provided, `along_x`, `along_y`, and `along_z` are ignored.\n\n    Returns:\n        ZarrNii: A new ZarrNii instance with the upsampled data and updated affine.\n\n    Notes:\n        - This method supports both direct scaling via `along_*` factors or target shape via `to_shape`.\n        - If `to_shape` is provided, chunk sizes and scaling factors are dynamically calculated.\n        - Currently, the method assumes `axes_order != 'XYZ'` for proper affine scaling.\n        - The affine matrix is updated to reflect the new voxel size after upsampling.\n\n    Example:\n        # Upsample with scaling factors\n        upsampled_znimg = znimg.upsample(along_x=2, along_y=2, along_z=2)\n\n        # Upsample to a specific shape\n        upsampled_znimg = znimg.upsample(to_shape=(1, 256, 256, 256))\n    \"\"\"\n    # Determine scaling and chunks based on input parameters\n    if to_shape is None:\n        if self.axes_order == \"XYZ\":\n            scaling = (1, along_x, along_y, along_z)\n        else:\n            scaling = (1, along_z, along_y, along_x)\n\n        chunks_out = tuple(\n            tuple(c * scale for c in chunks_i)\n            for chunks_i, scale in zip(self.darr.chunks, scaling)\n        )\n    else:\n        chunks_out, scaling = self.__get_upsampled_chunks(to_shape)\n\n    # Define block-wise upsampling function\n    def zoom_blocks(x, block_info=None):\n        \"\"\"\n        Scales blocks to the desired size using `scipy.ndimage.zoom`.\n\n        Parameters:\n            x (np.ndarray): Input block data.\n            block_info (dict, optional): Metadata about the current block.\n\n        Returns:\n            np.ndarray: The upscaled block.\n        \"\"\"\n        # Calculate scaling factors based on input and output chunk shapes\n        scaling = tuple(\n            out_n / in_n\n            for out_n, in_n in zip(block_info[None][\"chunk-shape\"], x.shape)\n        )\n        return zoom(x, scaling, order=1, prefilter=False)\n\n    # Perform block-wise upsampling\n    darr_scaled = da.map_blocks(\n        zoom_blocks, self.darr, dtype=self.darr.dtype, chunks=chunks_out\n    )\n\n    # Update the affine matrix to reflect the new voxel size\n    if self.axes_order == \"XYZ\":\n        scaling_matrix = np.diag(\n            (1 / scaling[1], 1 / scaling[2], 1 / scaling[3], 1)\n        )\n    else:\n        scaling_matrix = np.diag(\n            (1 / scaling[-1], 1 / scaling[-2], 1 / scaling[-3], 1)\n        )\n    new_affine = AffineTransform.from_array(scaling_matrix @ self.affine.matrix)\n\n    # Return a new ZarrNii instance with the upsampled data\n    return ZarrNii.from_darr(\n        darr_scaled.rechunk(), affine=new_affine, axes_order=self.axes_order\n    )\n</code></pre>"},{"location":"reference/#zarrnii.ZarrNii.upsample--upsample-with-scaling-factors","title":"Upsample with scaling factors","text":"<p>upsampled_znimg = znimg.upsample(along_x=2, along_y=2, along_z=2)</p>"},{"location":"reference/#zarrnii.ZarrNii.upsample--upsample-to-a-specific-shape","title":"Upsample to a specific shape","text":"<p>upsampled_znimg = znimg.upsample(to_shape=(1, 256, 256, 256))</p>"},{"location":"reference/#zarrnii.transform.AffineTransform.matrix","title":"<code>matrix = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/#zarrnii.transform.AffineTransform.__array__","title":"<code>__array__()</code>","text":"<p>Define how the object behaves when converted to a numpy array. Returns the matrix of the affine transform.</p> Source code in <code>zarrnii/transform.py</code> <pre><code>def __array__(self):\n    \"\"\"\n    Define how the object behaves when converted to a numpy array.\n    Returns the matrix of the affine transform.\n    \"\"\"\n    return self.matrix\n</code></pre>"},{"location":"reference/#zarrnii.transform.AffineTransform.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Enable array-like indexing on the matrix.</p> Source code in <code>zarrnii/transform.py</code> <pre><code>def __getitem__(self, key):\n    \"\"\"\n    Enable array-like indexing on the matrix.\n    \"\"\"\n    return self.matrix[key]\n</code></pre>"},{"location":"reference/#zarrnii.transform.AffineTransform.__matmul__","title":"<code>__matmul__(other)</code>","text":"<p>Perform matrix multiplication with another object.</p> <ul> <li>other (np.ndarray or AffineTransform): The object to multiply with:<ul> <li>(3,) or (3, 1): A 3D point or vector (voxel coordinates).</li> <li>(3, N): A batch of N 3D points or vectors (voxel coordinates).</li> <li>(4,) or (4, 1): A 4D point/vector in homogeneous coordinates.</li> <li>(4, N): A batch of N 4D points in homogeneous coordinates.</li> <li>(4, 4): Another affine transformation matrix.</li> </ul> </li> </ul> <ul> <li>np.ndarray or AffineTransform:<ul> <li>Transformed 3D point(s) or vector(s) as a numpy array.</li> <li>A new AffineTransform object if multiplying two affine matrices.</li> </ul> </li> </ul> <p>Raises: - ValueError: If the shape of <code>other</code> is unsupported. - TypeError: If <code>other</code> is not an np.ndarray or AffineTransform.</p> Source code in <code>zarrnii/transform.py</code> <pre><code>def __matmul__(self, other):\n    \"\"\"\n    Perform matrix multiplication with another object.\n\n    Parameters:\n    - other (np.ndarray or AffineTransform): The object to multiply with:\n        - (3,) or (3, 1): A 3D point or vector (voxel coordinates).\n        - (3, N): A batch of N 3D points or vectors (voxel coordinates).\n        - (4,) or (4, 1): A 4D point/vector in homogeneous coordinates.\n        - (4, N): A batch of N 4D points in homogeneous coordinates.\n        - (4, 4): Another affine transformation matrix.\n\n    Returns:\n    - np.ndarray or AffineTransform:\n        - Transformed 3D point(s) or vector(s) as a numpy array.\n        - A new AffineTransform object if multiplying two affine matrices.\n\n    Raises:\n    - ValueError: If the shape of `other` is unsupported.\n    - TypeError: If `other` is not an np.ndarray or AffineTransform.\n    \"\"\"\n    if isinstance(other, np.ndarray):\n        if other.shape == (3,):\n            # Single 3D point/vector\n            homog_point = np.append(other, 1)  # Convert to homogeneous coordinates\n            result = self.matrix @ homog_point\n            return result[:3] / result[3]  # Convert back to 3D\n        elif len(other.shape) == 2 and other.shape[0] == 3:\n            # Batch of 3D points/vectors (3 x N)\n            homog_points = np.vstack(\n                [other, np.ones((1, other.shape[1]))]\n            )  # Add homogeneous row\n            transformed_points = (\n                self.matrix @ homog_points\n            )  # Apply affine transform\n            return (\n                transformed_points[:3] / transformed_points[3]\n            )  # Convert back to 3D\n        elif other.shape == (4,):\n            # Single 4D point/vector\n            result = self.matrix @ other\n            return result[:3] / result[3]\n        elif len(other.shape) == 2 and other.shape[0] == 4:\n            # Batch of 4D points in homogeneous coordinates (4 x N)\n            transformed_points = self.matrix @ other  # Apply affine transform\n            return transformed_points  # No conversion needed, stays in 4D space\n        elif other.shape == (4, 4):\n            # Matrix multiplication with another affine matrix\n            return AffineTransform.from_array(self.matrix @ other)\n        else:\n            raise ValueError(f\"Unsupported shape for multiplication: {other.shape}\")\n    elif isinstance(other, AffineTransform):\n        # Matrix multiplication with another AffineTransform object\n        return AffineTransform.from_array(self.matrix @ other.matrix)\n    else:\n        raise TypeError(f\"Unsupported type for multiplication: {type(other)}\")\n</code></pre>"},{"location":"reference/#zarrnii.transform.AffineTransform.__setitem__","title":"<code>__setitem__(key, value)</code>","text":"<p>Enable array-like assignment to the matrix.</p> Source code in <code>zarrnii/transform.py</code> <pre><code>def __setitem__(self, key, value):\n    \"\"\"\n    Enable array-like assignment to the matrix.\n    \"\"\"\n    self.matrix[key] = value\n</code></pre>"},{"location":"reference/#zarrnii.transform.AffineTransform.apply_transform","title":"<code>apply_transform(vecs)</code>","text":"Source code in <code>zarrnii/transform.py</code> <pre><code>def apply_transform(self, vecs: np.array) -&gt; np.array:\n    return self @ vecs\n</code></pre>"},{"location":"reference/#zarrnii.transform.AffineTransform.from_array","title":"<code>from_array(matrix, invert=False)</code>  <code>classmethod</code>","text":"Source code in <code>zarrnii/transform.py</code> <pre><code>@classmethod\ndef from_array(cls, matrix, invert=False):\n    if invert:\n        matrix = np.linalg.inv(matrix)\n\n    return cls(matrix=matrix)\n</code></pre>"},{"location":"reference/#zarrnii.transform.AffineTransform.from_txt","title":"<code>from_txt(path, invert=False)</code>  <code>classmethod</code>","text":"Source code in <code>zarrnii/transform.py</code> <pre><code>@classmethod\ndef from_txt(cls, path, invert=False):\n    matrix = np.loadtxt(path)\n    if invert:\n        matrix = np.linalg.inv(matrix)\n\n    return cls(matrix=matrix)\n</code></pre>"},{"location":"reference/#zarrnii.transform.AffineTransform.identity","title":"<code>identity()</code>  <code>classmethod</code>","text":"Source code in <code>zarrnii/transform.py</code> <pre><code>@classmethod\ndef identity(cls):\n    return cls(matrix=np.eye(4, 4))\n</code></pre>"},{"location":"reference/#zarrnii.transform.AffineTransform.invert","title":"<code>invert()</code>","text":"<p>Return the inverse of the matrix transformation.</p> Source code in <code>zarrnii/transform.py</code> <pre><code>def invert(self):\n    \"\"\"Return the inverse of the matrix transformation.\"\"\"\n    return AffineTransform.from_array(np.linalg.inv(self.matrix))\n</code></pre>"},{"location":"reference/#zarrnii.transform.AffineTransform.update_for_orientation","title":"<code>update_for_orientation(input_orientation, output_orientation)</code>","text":"<p>Update the matrix to map from the input orientation to the output orientation.</p> <p>Parameters:</p> Name Type Description Default <code>input_orientation</code> <code>str</code> <p>Current anatomical orientation (e.g., 'RPI').</p> required <code>output_orientation</code> <code>str</code> <p>Target anatomical orientation (e.g., 'RAS').</p> required Source code in <code>zarrnii/transform.py</code> <pre><code>def update_for_orientation(self, input_orientation, output_orientation):\n    \"\"\"\n    Update the matrix to map from the input orientation to the output orientation.\n\n    Parameters:\n        input_orientation (str): Current anatomical orientation (e.g., 'RPI').\n        output_orientation (str): Target anatomical orientation (e.g., 'RAS').\n    \"\"\"\n\n    # Define a mapping of anatomical directions to axis indices and flips\n    axis_map = {\n        \"R\": (0, 1),\n        \"L\": (0, -1),\n        \"A\": (1, 1),\n        \"P\": (1, -1),\n        \"S\": (2, 1),\n        \"I\": (2, -1),\n    }\n\n    # Parse the input and output orientations\n    input_axes = [axis_map[ax] for ax in input_orientation]\n    output_axes = [axis_map[ax] for ax in output_orientation]\n\n    # Create a mapping from input to output\n    reorder_indices = [None] * 3\n    flip_signs = [1] * 3\n\n    for out_idx, (out_axis, out_sign) in enumerate(output_axes):\n        for in_idx, (in_axis, in_sign) in enumerate(input_axes):\n            if out_axis == in_axis:  # Match axis\n                reorder_indices[out_idx] = in_idx\n                flip_signs[out_idx] = out_sign * in_sign\n                break\n\n    # Reorder and flip the affine matrix\n    reordered_matrix = np.zeros_like(self.matrix)\n    for i, (reorder_idx, flip_sign) in enumerate(zip(reorder_indices, flip_signs)):\n        if reorder_idx is None:\n            raise ValueError(\n                f\"Cannot match all axes from {input_orientation} to {output_orientation}.\"\n            )\n        reordered_matrix[i, :3] = flip_sign * self.matrix[reorder_idx, :3]\n        reordered_matrix[i, 3] = flip_sign * self.matrix[reorder_idx, 3]\n    reordered_matrix[3, :] = self.matrix[3, :]  # Preserve the homogeneous row\n\n    return AffineTransform.from_array(reordered_matrix)\n</code></pre>"},{"location":"examples/zarr_nifti/","title":"Examples: Working with Zarr and NIfTI","text":"<p>This section provides practical workflows for using ZarrNii with OME-Zarr and NIfTI datasets.</p>"},{"location":"examples/zarr_nifti/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Loading Datasets<ul> <li>From OME-Zarr</li> <li>From NIfTI</li> </ul> </li> <li>Performing Transformations<ul> <li>Downsampling</li> <li>Cropping</li> <li>Combining Affine Transformations</li> </ul> </li> <li>Saving Results<ul> <li>To OME-Zarr</li> <li>To NIfTI</li> </ul> </li> <li>Advanced Example: Full Workflow</li> </ol>"},{"location":"examples/zarr_nifti/#loading-datasets","title":"Loading Datasets","text":""},{"location":"examples/zarr_nifti/#from-ome-zarr","title":"From OME-Zarr","text":"<p>Load a dataset from an OME-Zarr file and inspect its metadata:</p> <pre><code>from zarrnii import ZarrNii\n\n# Load OME-Zarr dataset\nznimg = ZarrNii.from_ome_zarr(\"path/to/dataset.zarr\")\n\n# Inspect data\nprint(\"Shape:\", znimg.darr.shape)\nprint(\"Affine matrix:\\n\", znimg.affine.matrix)\n</code></pre>"},{"location":"examples/zarr_nifti/#from-nifti","title":"From NIfTI","text":"<p>Load a NIfTI dataset and inspect its attributes:</p> <pre><code># Load NIfTI dataset\nznimg = ZarrNii.from_nifti(\"path/to/dataset.nii\")\n\n# Inspect data\nprint(\"Shape:\", znimg.darr.shape)\nprint(\"Affine matrix:\\n\", znimg.affine.matrix)\n</code></pre>"},{"location":"examples/zarr_nifti/#performing-transformations","title":"Performing Transformations","text":""},{"location":"examples/zarr_nifti/#downsampling","title":"Downsampling","text":"<p>Reduce the resolution of the dataset using the <code>downsample</code> method:</p> <pre><code># Downsample by level\ndownsampled = znimg.downsample(level=2)\nprint(\"Downsampled shape:\", downsampled.darr.shape)\n</code></pre>"},{"location":"examples/zarr_nifti/#cropping","title":"Cropping","text":"<p>Extract a specific region from the dataset using bounding boxes:</p>"},{"location":"examples/zarr_nifti/#voxel-space","title":"Voxel Space:","text":"<pre><code>cropped = znimg.crop_with_bounding_box((10, 10, 10), (50, 50, 50))\nprint(\"Cropped shape:\", cropped.darr.shape)\n</code></pre>"},{"location":"examples/zarr_nifti/#ras-space","title":"RAS Space:","text":"<pre><code>cropped_ras = znimg.crop_with_bounding_box(\n    (-20, -20, -20), (20, 20, 20), ras_coords=True\n)\nprint(\"Cropped shape:\", cropped_ras.darr.shape)\n</code></pre>"},{"location":"examples/zarr_nifti/#combining-affine-transformations","title":"Combining Affine Transformations","text":"<p>Apply multiple transformations to the dataset in sequence:</p> <pre><code>from zarrnii.transforms import AffineTransform\n\n# Define transformations\nscale = AffineTransform.from_scaling((2.0, 2.0, 1.0))\ntranslate = AffineTransform.from_translation((10.0, -5.0, 0.0))\n\n# Apply transformations\ntransformed = znimg.apply_transform(scale, translate, ref_znimg=znimg)\nprint(\"Transformed affine matrix:\\n\", transformed.affine.matrix)\n</code></pre>"},{"location":"examples/zarr_nifti/#saving-results","title":"Saving Results","text":""},{"location":"examples/zarr_nifti/#to-ome-zarr","title":"To OME-Zarr","text":"<p>Save the dataset to OME-Zarr format:</p> <pre><code>znimg.to_ome_zarr(\"output.zarr\", max_layer=3, scaling_method=\"local_mean\")\n</code></pre>"},{"location":"examples/zarr_nifti/#to-nifti","title":"To NIfTI","text":"<p>Save the dataset to NIfTI format:</p> <pre><code>znimg.to_nifti(\"output.nii\")\n</code></pre>"},{"location":"examples/zarr_nifti/#advanced-example-full-workflow","title":"Advanced Example: Full Workflow","text":"<p>Combine multiple operations in a single workflow:</p> <pre><code>from zarrnii import ZarrNii\nfrom zarrnii.transforms import AffineTransform\n\n# Load an OME-Zarr dataset\nznimg = ZarrNii.from_ome_zarr(\"path/to/dataset.zarr\")\n\n# Crop the dataset\ncropped = znimg.crop_with_bounding_box((10, 10, 10), (100, 100, 100))\n\n# Downsample the dataset\ndownsampled = cropped.downsample(level=2)\n\n# Apply an affine transformation\nscale = AffineTransform.from_scaling((1.5, 1.5, 1.0))\ntransformed = downsampled.apply_transform(scale, ref_znimg=downsampled)\n\n# Save the result as a NIfTI file\ntransformed.to_nifti(\"final_output.nii\")\n</code></pre>"},{"location":"examples/zarr_nifti/#summary","title":"Summary","text":"<p>In this section, you learned how to: - Load datasets from OME-Zarr and NIfTI formats. - Perform transformations like downsampling, cropping, and affine transformations. - Save results back to OME-Zarr or NIfTI.</p> <p>Next: - Explore the API Reference for in-depth details about ZarrNii's classes and methods. - Check the FAQ for answers to common questions.</p>"},{"location":"walkthrough/advanced_use_cases/","title":"Walkthrough: Advanced Use Cases","text":"<p>This guide explores advanced workflows with ZarrNii, including metadata preservation, handling multiscale OME-Zarr pyramids, and combining multiple transformations.</p>"},{"location":"walkthrough/advanced_use_cases/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Preserving Metadata</li> <li>Working with Multiscale Pyramids</li> <li>Combining Transformations</li> <li>Handling Large Datasets</li> </ol>"},{"location":"walkthrough/advanced_use_cases/#preserving-metadata","title":"Preserving Metadata","text":"<p>ZarrNii is designed to handle and preserve metadata when converting between formats or applying transformations.</p>"},{"location":"walkthrough/advanced_use_cases/#accessing-metadata","title":"Accessing Metadata","text":"<p>OME-Zarr metadata is automatically extracted and stored in the <code>axes</code>, <code>coordinate_transformations</code>, and <code>omero</code> attributes of a <code>ZarrNii</code> instance.</p> <pre><code>znimg = ZarrNii.from_ome_zarr(\"path/to/dataset.zarr\")\n\n# Access axes metadata\nprint(\"Axes metadata:\", znimg.axes)\n\n# Access coordinate transformations\nprint(\"Coordinate transformations:\", znimg.coordinate_transformations)\n\n# Access Omero metadata\nprint(\"Omero metadata:\", znimg.omero)\n</code></pre>"},{"location":"walkthrough/advanced_use_cases/#preserving-metadata-during-transformations","title":"Preserving Metadata During Transformations","text":"<p>When you perform transformations like cropping or downsampling, ZarrNii ensures metadata remains consistent.</p> <pre><code>cropped = znimg.crop_with_bounding_box((10, 10, 10), (50, 50, 50))\nprint(\"Updated metadata:\", cropped.coordinate_transformations)\n</code></pre>"},{"location":"walkthrough/advanced_use_cases/#working-with-multiscale-pyramids","title":"Working with Multiscale Pyramids","text":"<p>OME-Zarr datasets often include multiscale pyramids, where each level represents a progressively downsampled version of the data.</p>"},{"location":"walkthrough/advanced_use_cases/#loading-a-specific-level","title":"Loading a Specific Level","text":"<p>You can load a specific pyramid level using the <code>level</code> argument in <code>from_ome_zarr</code>:</p> <pre><code>znimg = ZarrNii.from_ome_zarr(\"path/to/dataset.zarr\", level=2)\nprint(\"Loaded shape:\", znimg.darr.shape)\n</code></pre>"},{"location":"walkthrough/advanced_use_cases/#handling-custom-downsampling","title":"Handling Custom Downsampling","text":"<p>If the desired level isn't available in the pyramid, ZarrNii computes additional downsampling lazily:</p> <pre><code>level, do_downsample, ds_kwargs = ZarrNii.get_level_and_downsampling_kwargs(\n    \"path/to/dataset.zarr\", level=5\n)\nif do_downsample:\n    znimg = znimg.downsample(**ds_kwargs)\n</code></pre>"},{"location":"walkthrough/advanced_use_cases/#combining-transformations","title":"Combining Transformations","text":"<p>ZarrNii allows you to chain multiple transformations into a single workflow. This is useful when applying affine transformations, interpolations, or warping.</p>"},{"location":"walkthrough/advanced_use_cases/#chaining-affine-transformations","title":"Chaining Affine Transformations","text":"<pre><code>from zarrnii.transforms import AffineTransform\n\n# Create multiple transformations\nscaling = AffineTransform.from_scaling((2.0, 2.0, 1.0))\ntranslation = AffineTransform.from_translation((10.0, -5.0, 0.0))\n\n# Combine and apply transformations\ncombined = znimg.apply_transform(scaling, translation, ref_znimg=znimg)\nprint(\"New affine matrix:\\n\", combined.affine.matrix)\n</code></pre>"},{"location":"walkthrough/advanced_use_cases/#handling-large-datasets","title":"Handling Large Datasets","text":"<p>ZarrNii leverages Dask to handle datasets that don't fit into memory.</p>"},{"location":"walkthrough/advanced_use_cases/#optimizing-chunking","title":"Optimizing Chunking","text":"<p>Ensure the dataset is chunked appropriately for operations like downsampling or interpolation:</p> <pre><code># Rechunk for efficient processing\nrechunked = znimg.darr.rechunk((1, 64, 64, 64))\nprint(\"Rechunked shape:\", rechunked.shape)\n</code></pre>"},{"location":"walkthrough/advanced_use_cases/#lazy-evaluation","title":"Lazy Evaluation","text":"<p>Most transformations in ZarrNii are lazy, meaning computations are only triggered when necessary. Use <code>.compute()</code> to materialize results.</p> <pre><code># Trigger computation\ncropped = znimg.crop_with_bounding_box((10, 10, 10), (50, 50, 50))\ncropped.darr.compute()\n</code></pre>"},{"location":"walkthrough/advanced_use_cases/#summary","title":"Summary","text":"<p>This guide covered: - Preserving metadata across transformations and format conversions. - Working with multiscale pyramids in OME-Zarr. - Combining transformations for complex workflows. - Handling large datasets efficiently with Dask.</p> <p>Next, explore: - Examples: Detailed workflows and practical use cases. - API Reference: Technical details for ZarrNii classes and methods.</p>"},{"location":"walkthrough/basic_tasks/","title":"Walkthrough: Basic Tasks","text":"<p>This guide covers the most common tasks you'll perform with ZarrNii, including reading data, performing transformations, and saving results.</p>"},{"location":"walkthrough/basic_tasks/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Reading Data<ul> <li>From OME-Zarr</li> <li>From NIfTI</li> </ul> </li> <li>Transforming Data<ul> <li>Cropping</li> <li>Downsampling</li> <li>Upsampling</li> <li>Applying Affine Transformations</li> </ul> </li> <li>Saving Data<ul> <li>To NIfTI</li> <li>To OME-Zarr</li> </ul> </li> </ol>"},{"location":"walkthrough/basic_tasks/#reading-data","title":"Reading Data","text":""},{"location":"walkthrough/basic_tasks/#from-ome-zarr","title":"From OME-Zarr","text":"<p>Load a dataset from an OME-Zarr file using <code>from_ome_zarr</code>:</p> <pre><code>from zarrnii import ZarrNii\n\n# Load the dataset\nznimg = ZarrNii.from_ome_zarr(\"path/to/dataset.ome.zarr\")\n\n# Inspect the data\nprint(\"Data shape:\", znimg.darr.shape)\nprint(\"Affine matrix:\\n\", znimg.affine.matrix)\n</code></pre>"},{"location":"walkthrough/basic_tasks/#from-nifti","title":"From NIfTI","text":"<p>Load a dataset from a NIfTI file using <code>from_nifti</code>:</p> <pre><code># Load the dataset\nznimg = ZarrNii.from_nifti(\"path/to/dataset.nii\")\n\n# Inspect the data\nprint(\"Data shape:\", znimg.darr.shape)\nprint(\"Affine matrix:\\n\", znimg.affine.matrix)\n</code></pre>"},{"location":"walkthrough/basic_tasks/#transforming-data","title":"Transforming Data","text":""},{"location":"walkthrough/basic_tasks/#cropping","title":"Cropping","text":"<p>Crop the dataset to a specific bounding box. You can define the bounding box in either voxel space or RAS (real-world) coordinates.</p>"},{"location":"walkthrough/basic_tasks/#voxel-space-cropping","title":"Voxel Space Cropping:","text":"<pre><code>cropped = znimg.crop_with_bounding_box((10, 10, 10), (50, 50, 50))\nprint(\"Cropped shape:\", cropped.darr.shape)\n</code></pre>"},{"location":"walkthrough/basic_tasks/#ras-space-cropping","title":"RAS Space Cropping:","text":"<pre><code>cropped_ras = znimg.crop_with_bounding_box(\n    (-20, -20, -20), (20, 20, 20), ras_coords=True\n)\nprint(\"Cropped shape:\", cropped_ras.darr.shape)\n</code></pre>"},{"location":"walkthrough/basic_tasks/#downsampling","title":"Downsampling","text":"<p>Downsample the dataset to reduce its resolution. You can specify either a downsampling level or individual scaling factors for each axis.</p>"},{"location":"walkthrough/basic_tasks/#by-level","title":"By Level:","text":"<pre><code>downsampled = znimg.downsample(level=2)\nprint(\"Downsampled shape:\", downsampled.darr.shape)\n</code></pre>"},{"location":"walkthrough/basic_tasks/#by-scaling-factors","title":"By Scaling Factors:","text":"<pre><code>downsampled_manual = znimg.downsample(along_x=2, along_y=2, along_z=1)\nprint(\"Downsampled shape:\", downsampled_manual.darr.shape)\n</code></pre>"},{"location":"walkthrough/basic_tasks/#upsampling","title":"Upsampling","text":"<p>Increase the resolution of the dataset by upsampling.</p>"},{"location":"walkthrough/basic_tasks/#by-scaling-factors_1","title":"By Scaling Factors:","text":"<pre><code>upsampled = znimg.upsample(along_x=2, along_y=2, along_z=2)\nprint(\"Upsampled shape:\", upsampled.darr.shape)\n</code></pre>"},{"location":"walkthrough/basic_tasks/#to-target-shape","title":"To Target Shape:","text":"<pre><code>upsampled_target = znimg.upsample(to_shape=(1, 256, 256, 256))\nprint(\"Upsampled shape:\", upsampled_target.darr.shape)\n</code></pre>"},{"location":"walkthrough/basic_tasks/#applying-affine-transformations","title":"Applying Affine Transformations","text":"<p>Apply a custom affine transformation to the dataset.</p> <pre><code>from zarrnii.transforms import AffineTransform\n\n# Define a scaling transformation\nscaling_transform = AffineTransform.from_scaling((2.0, 2.0, 1.0))\n\n# Apply the transformation\ntransformed = znimg.apply_transform(scaling_transform, znimg)\nprint(\"Transformed affine matrix:\\n\", transformed.affine.matrix)\n</code></pre>"},{"location":"walkthrough/basic_tasks/#saving-data","title":"Saving Data","text":""},{"location":"walkthrough/basic_tasks/#to-nifti","title":"To NIfTI","text":"<p>Save the dataset as a NIfTI file using <code>to_nifti</code>:</p> <pre><code>znimg.to_nifti(\"output_dataset.nii\")\n</code></pre>"},{"location":"walkthrough/basic_tasks/#to-ome-zarr","title":"To OME-Zarr","text":"<p>Save the dataset as an OME-Zarr file using <code>to_ome_zarr</code>:</p> <pre><code>znimg.to_ome_zarr(\"output_dataset.ome.zarr\")\n</code></pre> <p>You can also save additional metadata during the process:</p> <pre><code>znimg.to_ome_zarr(\n    \"output_dataset.ome.zarr\",\n    max_layer=3,\n    scaling_method=\"local_mean\"\n)\n</code></pre>"},{"location":"walkthrough/basic_tasks/#summary","title":"Summary","text":"<p>This guide covered the essential operations you can perform with ZarrNii: - Reading datasets from OME-Zarr and NIfTI formats. - Transforming datasets through cropping, downsampling, upsampling, and affine transformations. - Saving datasets back to either format.</p> <p>Next, explore Advanced Use Cases or dive into the API Reference for detailed technical documentation.</p>"},{"location":"walkthrough/getting_started/","title":"Getting Started","text":"<p>This guide helps you set up ZarrNii and get started with its basic functionality. By the end of this guide, you'll be able to read OME-Zarr and NIfTI datasets, perform basic transformations, and save your results.</p>"},{"location":"walkthrough/getting_started/#installation","title":"Installation","text":"<p>ZarrNii requires Python 3.10 or later. Install it using Poetry, a modern dependency manager for Python.</p>"},{"location":"walkthrough/getting_started/#1-clone-the-repository","title":"1. Clone the Repository","text":"<p>If you're using the source code, clone the ZarrNii repository:</p> <pre><code>git clone https://github.com/yourusername/zarrnii.git\ncd zarrnii\n</code></pre>"},{"location":"walkthrough/getting_started/#2-install-with-poetry","title":"2. Install with Poetry","text":"<p>Run the following command to install the library and its dependencies:</p> <pre><code>poetry install\n</code></pre> <p>If you don't use Poetry, install ZarrNii and its dependencies using <code>pip</code>:</p> <pre><code>pip install zarrnii\n</code></pre>"},{"location":"walkthrough/getting_started/#prerequisites","title":"Prerequisites","text":"<p>Before using ZarrNii, ensure you have: - OME-Zarr datasets: Multidimensional images in Zarr format. - NIfTI datasets: Neuroimaging data in <code>.nii</code> or <code>.nii.gz</code> format.</p>"},{"location":"walkthrough/getting_started/#basic-usage","title":"Basic Usage","text":""},{"location":"walkthrough/getting_started/#1-reading-data","title":"1. Reading Data","text":"<p>You can load an OME-Zarr or NIfTI dataset into a <code>ZarrNii</code> object.</p>"},{"location":"walkthrough/getting_started/#from-ome-zarr","title":"From OME-Zarr:","text":"<pre><code>from zarrnii import ZarrNii\n\n# Load OME-Zarr\nznimg = ZarrNii.from_ome_zarr(\"path/to/dataset.ome.zarr\")\n\nprint(\"Data shape:\", znimg.darr.shape)\nprint(\"Affine matrix:\\n\", znimg.affine.matrix)\n</code></pre>"},{"location":"walkthrough/getting_started/#from-nifti","title":"From NIfTI:","text":"<pre><code># Load NIfTI\nznimg = ZarrNii.from_nifti(\"path/to/dataset.nii\")\n\nprint(\"Data shape:\", znimg.darr.shape)\nprint(\"Affine matrix:\\n\", znimg.affine.matrix)\n</code></pre>"},{"location":"walkthrough/getting_started/#2-performing-transformations","title":"2. Performing Transformations","text":"<p>ZarrNii supports various transformations, such as cropping, downsampling, and upsampling.</p>"},{"location":"walkthrough/getting_started/#cropping","title":"Cropping:","text":"<p>Crop a region from the dataset using voxel or RAS (real-world) coordinates:</p> <pre><code>cropped = znimg.crop_with_bounding_box((10, 10, 10), (50, 50, 50))\nprint(\"Cropped shape:\", cropped.darr.shape)\n</code></pre>"},{"location":"walkthrough/getting_started/#downsampling","title":"Downsampling:","text":"<p>Reduce the resolution of your dataset:</p> <pre><code>downsampled = znimg.downsample(level=2)\nprint(\"Downsampled shape:\", downsampled.darr.shape)\n</code></pre>"},{"location":"walkthrough/getting_started/#upsampling","title":"Upsampling:","text":"<p>Increase the resolution of your dataset:</p> <pre><code>upsampled = znimg.upsample(along_x=2, along_y=2, along_z=2)\nprint(\"Upsampled shape:\", upsampled.darr.shape)\n</code></pre>"},{"location":"walkthrough/getting_started/#3-saving-data","title":"3. Saving Data","text":"<p>ZarrNii makes it easy to save your datasets in both OME-Zarr and NIfTI formats.</p>"},{"location":"walkthrough/getting_started/#to-nifti","title":"To NIfTI:","text":"<p>Save the dataset as a <code>.nii</code> file:</p> <pre><code>znimg.to_nifti(\"output_dataset.nii\")\n</code></pre>"},{"location":"walkthrough/getting_started/#to-ome-zarr","title":"To OME-Zarr:","text":"<p>Save the dataset back to OME-Zarr format:</p> <pre><code>znimg.to_ome_zarr(\"output_dataset.ome.zarr\")\n</code></pre>"},{"location":"walkthrough/getting_started/#example-workflow","title":"Example Workflow","text":"<p>Here\u2019s a full workflow from loading an OME-Zarr dataset to saving a downsampled version as NIfTI:</p> <pre><code>from zarrnii import ZarrNii\n\n# Load an OME-Zarr dataset\nznimg = ZarrNii.from_ome_zarr(\"path/to/dataset.ome.zarr\")\n\n# Perform transformations\ncropped = znimg.crop_with_bounding_box((10, 10, 10), (100, 100, 100))\ndownsampled = cropped.downsample(level=2)\n\n# Save the result as a NIfTI file\ndownsampled.to_nifti(\"downsampled_output.nii\")\n</code></pre>"},{"location":"walkthrough/getting_started/#whats-next","title":"What\u2019s Next?","text":"<ul> <li>Walkthrough: Basic Tasks: Learn more about common workflows like cropping, interpolation, and combining transformations.</li> <li>API Reference: Explore the detailed API for ZarrNii.</li> </ul>"},{"location":"walkthrough/overview/","title":"Walkthrough: Overview","text":"<p>This page provides an overview of the core concepts behind ZarrNii. It\u2019s the starting point for understanding how to work with OME-Zarr, NIfTI, and ZarrNii\u2019s transformation tools.</p>"},{"location":"walkthrough/overview/#core-concepts","title":"Core Concepts","text":""},{"location":"walkthrough/overview/#1-zarr-and-ome-zarr","title":"1. Zarr and OME-Zarr","text":"<ul> <li>Zarr is a format for chunked, compressed N-dimensional arrays.</li> <li>OME-Zarr extends Zarr with metadata for multidimensional microscopy images, supporting axes definitions and multiscale pyramids.</li> </ul>"},{"location":"walkthrough/overview/#key-features-of-ome-zarr","title":"Key Features of OME-Zarr:","text":"<ul> <li>Axes Metadata: Defines spatial dimensions (e.g., <code>x</code>, <code>y</code>, <code>z</code>).</li> <li>Multiscale Pyramids: Stores image resolutions at multiple scales.</li> <li>Annotations: Includes OME metadata for visualization and analysis.</li> </ul>"},{"location":"walkthrough/overview/#2-nifti","title":"2. NIfTI","text":"<ul> <li>NIfTI is a neuroimaging file format, commonly used for MRI and fMRI data.</li> <li>It supports spatial metadata, such as voxel sizes and affine transformations, for anatomical alignment.</li> </ul>"},{"location":"walkthrough/overview/#3-zarrnii","title":"3. ZarrNii","text":"<ul> <li>ZarrNii provides tools to bridge these formats while preserving spatial metadata and enabling transformations.</li> </ul>"},{"location":"walkthrough/overview/#main-features","title":"Main Features:","text":"<ul> <li>Read and write OME-Zarr and NIfTI formats.</li> <li>Apply transformations like cropping, downsampling, and interpolation.</li> <li>Convert between ZYX (OME-Zarr) and XYZ (NIfTI) axes orders.</li> </ul>"},{"location":"walkthrough/overview/#data-model","title":"Data Model","text":"<p>ZarrNii wraps datasets using the <code>ZarrNii</code> class, which has the following attributes:</p> <ul> <li><code>darr</code>: The dask array containing image data.</li> <li><code>affine</code>: An affine transformation matrix for spatial alignment.</li> <li><code>axes_order</code>: Specifies the data layout (<code>ZYX</code> or <code>XYZ</code>).</li> <li>OME-Zarr Metadata:</li> <li><code>axes</code>: Defines the dimensions and units.</li> <li><code>coordinate_transformations</code>: Lists scaling and translation transformations.</li> <li><code>omero</code>: Contains channel and visualization metadata.</li> </ul>"},{"location":"walkthrough/overview/#example-workflow","title":"Example Workflow","text":"<p>Here\u2019s a high-level example workflow using ZarrNii:</p> <ol> <li> <p>Read Data:    <code>python    from zarrnii import ZarrNii    znimg = ZarrNii.from_ome_zarr(\"path/to/dataset.ome.zarr\")</code></p> </li> <li> <p>Apply Transformations:    <code>python    znimg_downsampled = znimg.downsample(level=2)    znimg_cropped = znimg_downsampled.crop_with_bounding_box((0, 0, 0), (100, 100, 100))</code></p> </li> <li> <p>Convert Formats:    <code>python    znimg_cropped.to_nifti(\"output.nii\")</code></p> </li> </ol>"},{"location":"walkthrough/overview/#whats-next","title":"What\u2019s Next?","text":"<ul> <li>Getting Started: Step-by-step guide to installing and using ZarrNii.</li> <li>Basic Tasks: Learn how to read, write, and transform data.</li> </ul>"}]}